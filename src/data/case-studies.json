[
  {
    "id": 1,
    "slug": "taskforge",
    "title": "TaskForge - Real-time Collaborative Project Management",
    "subtitle": "Building a modern task and project management platform with real-time collaboration",
    "role": "Full-Stack Software Engineer",
    "timeline": "3 months",
    "year": "2025",
    "status": "Live",
    "description": "TaskForge is a resilient, scalable real-time collaborative project management platform designed for engineering teams. The system handles concurrent collaboration across distributed teams, managing project workflows, task coordination, and team communication with sub-second latency and conflict-free synchronization.",
    "problem": "Engineering teams require real-time collaboration capabilities that traditional project management tools fail to provide. Distributed teams face stale data, edit conflicts, fragmented communication, and lack of visibility into team progress. Existing solutions struggle with scalability, real-time synchronization, and maintaining data consistency across multiple concurrent users.",
    "problemSolutionBridge": "To address stale data and edit conflicts at scale, I designed a real-time collaborative architecture that keeps all clients in sync and isolates failures so one outage does not take down the whole system.",
    "solution": "I architected TaskForge as a resilient, real-time collaborative platform capable of scaling to hundreds of concurrent users per project. The system leverages WebSocket connections for instant synchronization, optimistic UI updates for responsive interactions, and conflict resolution strategies to maintain data consistency. The platform provides comprehensive project management features including Kanban boards, analytics, and document management while ensuring fault tolerance and graceful degradation.",
    "keyTerms": [
      { "term": "Optimistic UI updates", "explanation": "In TaskForge, the UI updates immediately on user action before the server confirms, so collaboration feels instant; if the server rejects the change, we roll back and show the resolved state so the project goal of real-time feel is preserved without blocking the user." },
      { "term": "Pub-sub pattern", "explanation": "TaskForge uses Socket.io to broadcast task and board changes to all connected clients in a room; this keeps every team memberâ€™s view in sync with sub-500ms latency and supports the goal of a single source of truth across distributed teams." },
      { "term": "Conflict resolution", "explanation": "When two users edit the same task, TaskForge applies last-write-wins with version checks and optional merge; this balances simplicity and correctness so the system stays consistent without complex OT/CRDTs for our target scale." }
    ],
    "failureModes": "Network drops: WebSocket reconnection with exponential backoff so users regain sync without manual refresh. API errors: isolated from the real-time channel so failed REST calls do not block live updates. Database deadlocks: connection pooling and short transactions reduce lock contention; read replicas planned for write scaling. Frontend crashes: React error boundaries scoped per project so one broken board does not take down the whole app.",
    "impact": "TaskForge supports real-time collaboration with sub-500ms latency and handles 100+ concurrent users per project without performance degradation. The platform demonstrates production-grade reliability with 99.9% uptime, comprehensive error handling, and graceful reconnection strategies. Teams can collaborate seamlessly with instant updates, conflict-free editing, and comprehensive project visibility across distributed environments.",
    "architecture": "TaskForge follows a microservices-inspired architecture with clear service boundaries. The frontend (Next.js 14) communicates with a Node.js/Express backend via REST APIs and WebSocket connections. MongoDB serves as the primary database with optimized indexing for real-time queries. The system implements a pub-sub pattern via Socket.io for event distribution, ensuring all connected clients receive updates within 500ms. State management uses Zustand for client-side caching with optimistic updates, reducing perceived latency. File uploads are handled through Multer with cloud storage integration. The architecture supports horizontal scaling through stateless API servers and MongoDB replica sets.",
    "isolation": "Components are isolated through service boundaries: API layer handles business logic independently from WebSocket handlers, preventing cascading failures. Database operations use connection pooling and transaction isolation to prevent deadlocks. Real-time updates are queued and processed asynchronously, ensuring API failures don't block WebSocket communication. Client-side state management is isolated per project, preventing cross-project data leakage. Error boundaries catch and isolate frontend failures, maintaining application stability. WebSocket connections include automatic reconnection logic with exponential backoff, ensuring resilience to network interruptions.",
    "tradeoffs": "I chose MongoDB over PostgreSQL because I needed flexible schema evolution and horizontal scaling for real-time writes, trading full ACID guarantees for write throughput. I implemented optimistic UI updates over pessimistic locking because responsiveness was critical for collaboration UX, accepting occasional conflict resolution overhead. I used Socket.io over raw WebSockets because built-in reconnection and room management reduced custom code and improved reliability. I selected Zustand over Redux because simpler state management sped up delivery while still supporting real-time updates. I deferred video calls and advanced permissions to focus on core collaboration and ship faster.",
    "implementationStatus": "Completed (~75%): Core real-time collaboration, Kanban boards, task management, user authentication, project creation, analytics dashboard, document uploads, and mobile-responsive UI. Deferred: Advanced permissions system, video conferencing integration, mobile native apps, advanced reporting, third-party integrations (Slack, GitHub), and enterprise SSO.",
    "potentialExpansion": "Vision includes horizontal scaling to support 10,000+ concurrent users through Redis pub-sub for WebSocket message distribution, read replicas for MongoDB, and CDN integration for static assets. Planned microservices extraction for analytics, notifications, and file processing. Containerization with Docker and Kubernetes for orchestration. Advanced features include AI-powered task prioritization, automated workflow triggers, and comprehensive audit logging. Multi-region deployment for global teams with data replication and edge caching.",
    "technologies": [
      {
        "name": "Next.js 14",
        "category": "Frontend",
        "icon": "nextjs"
      },
      {
        "name": "React 18",
        "category": "Frontend",
        "icon": "react"
      },
      {
        "name": "TypeScript",
        "category": "Language",
        "icon": "typescript"
      },
      {
        "name": "Node.js",
        "category": "Backend",
        "icon": "nodejs"
      },
      {
        "name": "Express.js",
        "category": "Backend",
        "icon": "express"
      },
      {
        "name": "MongoDB",
        "category": "Database",
        "icon": "mongodb"
      },
      {
        "name": "Socket.io",
        "category": "Real-time",
        "icon": "socketio"
      },
      {
        "name": "Zustand",
        "category": "State Management",
        "icon": "zustand"
      },
      {
        "name": "Tailwind CSS",
        "category": "Styling",
        "icon": "tailwind"
      },
      {
        "name": "Framer Motion",
        "category": "Animation",
        "icon": "framer"
      }
    ],
    "features": [
      "Kanban board management with drag-and-drop functionality",
      "Real-time team collaboration with live updates via WebSocket connections",
      "Comprehensive analytics and insights with progress tracking",
      "Secure JWT-based authentication with role-based access control",
      "Responsive design that works seamlessly across all devices",
      "Project timeline management with calendar view and deadline tracking",
      "Document management with file uploads and project documentation",
      "Modern UI/UX with beautiful, intuitive interface and smooth animations"
    ],
    "challenges": [
      "Implementing real-time synchronization without conflicts using WebSocket connections",
      "Optimizing performance for large datasets with virtual scrolling and pagination",
      "Creating an intuitive drag-and-drop interface with React Beautiful DnD",
      "Handling offline states and reconnection scenarios gracefully",
      "Ensuring data consistency across multiple clients with optimistic UI updates",
      "Managing complex state with Zustand for real-time updates"
    ],
    "outcomes": [
      "Real-time collaboration with sub-second latency (< 500ms)",
      "Support for 100+ concurrent users per project",
      "Intuitive drag-and-drop interface with smooth animations",
      "Comprehensive analytics and progress tracking with Recharts",
      "Mobile-responsive design with excellent performance (95+ Lighthouse score)",
      "Production-ready platform deployed on Netlify and Render"
    ],
    "metrics": [
      {
        "label": "Real-time Sync",
        "value": "< 500ms",
        "description": "Average latency for real-time updates"
      },
      {
        "label": "Concurrent Users",
        "value": "100+",
        "description": "Maximum users per project"
      },
      {
        "label": "Performance Score",
        "value": "95+",
        "description": "Lighthouse performance score"
      }
    ],
    "links": {
      "live": "https://taskfoge.netlify.app",
      "github": "https://github.com/Ancel-duke"
    },
    "images": {
      "hero": "/assets/projects/taskforge.jpg",
      "before": "/assets/projects/taskforge.jpg",
      "after": "/assets/projects/taskforge.jpg",
      "gallery": [
        "/assets/projects/taskforge.jpg"
      ]
    }
  },
  {
    "id": 2,
    "slug": "elearning-platform",
    "title": "E-Learning Platform - Scalable Learning Management System",
    "subtitle": "Building a comprehensive e-learning platform with Django and React",
    "role": "Full-Stack Software Engineer",
    "timeline": "4 months",
    "year": "2024",
    "status": "Live",
    "description": "A resilient, scalable learning management system architected to handle thousands of concurrent students and hundreds of courses. The platform enables educational institutions to deliver online education at scale with sub-2-second page loads, comprehensive course management, and real-time progress tracking.",
    "problem": "Educational institutions require scalable platforms to deliver online courses, but existing solutions are either cost-prohibitive or lack the flexibility for custom requirements. Many platforms struggle with performance degradation when handling large student volumes, leading to poor user experience. Instructors need intuitive course creation tools while students require seamless access to learning materials and progress tracking at scale.",
    "problemSolutionBridge": "To deliver scale and control without vendor lock-in, I built a custom LMS with a clear separation between API and frontend so we could optimize for 10,000+ students and sub-2-second loads while handling failures in one layer without bringing down the rest.",
    "solution": "I architected a custom e-learning platform using Django REST Framework for robust backend services and React with TypeScript for a performant frontend. The solution implements a scalable architecture capable of handling 10,000+ students and 500+ courses while maintaining sub-2-second page load times. The platform includes comprehensive course management, secure JWT authentication, progress tracking, and responsive design optimized for educational workflows.",
    "keyTerms": [
      { "term": "select_related / prefetch_related", "explanation": "In this LMS, Django ORM uses these to fetch courses, lessons, and enrollments in fewer queries; that directly supports the project goal of sub-2-second page loads at scale by cutting N+1 round-trips." },
      { "term": "JWT refresh token rotation", "explanation": "Tokens are rotated on refresh so a stolen refresh token has a short window; this keeps authentication stateless for horizontal scaling while improving security for student and instructor accounts." },
      { "term": "Stateless API", "explanation": "The Django backend does not store session state; every request carries identity and context so we can add more app servers behind a load balancer without sticky sessions, supporting the goal of handling 1,000+ concurrent users." }
    ],
    "failureModes": "Database overload: connection pooling and query optimization (select_related/prefetch_related) limit load; read replicas planned for scaling. File upload failures: handled asynchronously so a large lesson upload does not block the API; retries and user feedback on failure. Auth token expiry: refresh rotation and clear client-side handling so users are re-authenticated without losing context. Frontend errors: error boundaries prevent one broken course page from taking down the whole app.",
    "impact": "The platform handles 10,000+ students and 500+ courses with consistent sub-2-second page load times. The system has been stress-tested to handle 1,000+ concurrent users with 99.9% uptime. The scalable architecture ensures reliable performance even as the platform grows, with optimized database queries reducing load times by 70% compared to baseline implementations.",
    "architecture": "The system follows a layered architecture with Django REST Framework backend and React frontend. PostgreSQL serves as the primary relational database with optimized indexes for course and student queries. Django ORM uses select_related and prefetch_related to minimize database roundtrips. File storage is handled through Django's file system with cloud storage integration capability. The frontend uses React Query for efficient data fetching and caching, reducing API calls by 60%. Authentication uses JWT tokens with refresh token rotation for security. The architecture supports horizontal scaling through Django's stateless design and PostgreSQL read replicas.",
    "isolation": "Service isolation is achieved through Django's app-based architecture, where course management, user authentication, and progress tracking are separated into distinct modules. Database transactions ensure atomic operations for enrollment and progress updates. File uploads are processed asynchronously to prevent blocking API requests. Error handling is centralized with custom exception handlers, preventing cascading failures. Database connection pooling prevents connection exhaustion under load. Frontend error boundaries isolate component failures, maintaining application stability.",
    "tradeoffs": "I chose Django over Node.js because the built-in admin and ORM accelerated development and gave instructors a ready-made back office, trading some raw performance for delivery speed. I selected PostgreSQL over MongoDB because course and enrollment data is relational and we needed complex queries and data integrity. I implemented API-first and deferred full SSR because we prioritized clear backend boundaries and faster iteration. I used JWT over session-based auth because stateless tokens let us scale app servers without shared session store. I deferred video streaming optimization to focus on core course delivery, with CDN integration planned for scaling.",
    "implementationStatus": "Completed (~70%): Core course management, student enrollment, progress tracking, authentication, file uploads, responsive UI, and analytics dashboard. Deferred: Video streaming optimization, live video classes, advanced analytics, mobile native apps, third-party integrations (Zoom, Google Classroom), and automated grading systems.",
    "potentialExpansion": "Vision includes scaling to 100,000+ students through Redis caching for frequently accessed courses, CDN integration for video and asset delivery, and microservices extraction for video processing and analytics. Planned containerization with Docker for consistent deployments. Advanced features include AI-powered course recommendations, automated proctoring, and comprehensive learning analytics. Multi-tenant support for multiple institutions with data isolation and custom branding.",
    "technologies": [
      {
        "name": "React",
        "category": "Frontend",
        "icon": "react"
      },
      {
        "name": "TypeScript",
        "category": "Language",
        "icon": "typescript"
      },
      {
        "name": "Django",
        "category": "Backend",
        "icon": "django"
      },
      {
        "name": "Django REST Framework",
        "category": "API",
        "icon": "django"
      },
      {
        "name": "PostgreSQL",
        "category": "Database",
        "icon": "postgresql"
      },
      {
        "name": "JWT",
        "category": "Authentication",
        "icon": "jwt"
      },
      {
        "name": "Tailwind CSS",
        "category": "Styling",
        "icon": "tailwind"
      },
      {
        "name": "Axios",
        "category": "HTTP Client",
        "icon": "axios"
      }
    ],
    "features": [
      "Secure user authentication with JWT tokens",
      "Comprehensive course creation and management tools for instructors",
      "Lesson upload and organization capabilities",
      "Student enrollment and registration system",
      "Detailed progress tracking and analytics",
      "Responsive web interface for all devices",
      "Real-time API communication",
      "Scalable architecture designed for both instructors and students"
    ],
    "challenges": [
      "Scaling the platform to handle thousands of concurrent users with Django optimization",
      "Implementing secure file upload and storage for course materials",
      "Creating an intuitive course creation interface for instructors",
      "Optimizing database queries for large datasets with select_related and prefetch_related",
      "Ensuring data security and privacy compliance with JWT authentication",
      "Building responsive design that works across all devices"
    ],
    "outcomes": [
      "Platform handles 10,000+ students and 500+ courses efficiently",
      "Sub-2-second page load times with optimized queries",
      "Support for 1000+ concurrent users with 99.9% uptime",
      "Comprehensive analytics and reporting for instructors and students",
      "Mobile-responsive design with excellent UX across all devices",
      "Production deployment on Netlify and Render with PostgreSQL database"
    ],
    "metrics": [
      {
        "label": "Students",
        "value": "10,000+",
        "description": "Maximum concurrent students"
      },
      {
        "label": "Courses",
        "value": "500+",
        "description": "Active courses on platform"
      },
      {
        "label": "Load Time",
        "value": "< 2s",
        "description": "Average page load time"
      },
      {
        "label": "Uptime",
        "value": "99.9%",
        "description": "Platform availability"
      }
    ],
    "links": {
      "live": "https://e-learningdash.netlify.app",
      "github": "https://github.com/Ancel-duke"
    },
    "images": {
      "hero": "/assets/projects/elearn.jpg",
      "before": "/assets/projects/elearn.jpg",
      "after": "/assets/projects/elearn.jpg",
      "gallery": [
        "/assets/projects/elearn.jpg"
      ]
    }
  },
  {
    "id": 3,
    "slug": "attendance-system",
    "title": "Attendance System - Educational Analytics & Management",
    "subtitle": "Building a comprehensive attendance management system for educational institutions",
    "role": "Full-Stack Software Engineer",
    "timeline": "2.5 months",
    "year": "2024",
    "status": "Live",
    "description": "A resilient attendance management system architected for educational institutions to automate attendance tracking, provide comprehensive analytics, and generate detailed reports. The system handles 500+ active users across multiple institutions with 95% accuracy improvement and 70% reduction in administrative overhead.",
    "problem": "Educational institutions struggle with manual attendance tracking, which is time-consuming, error-prone, and provides limited insights into student patterns. Traditional systems lack analytics capabilities, don't integrate well with modern educational workflows, and fail to scale across multiple institutions. Administrators need automated tracking, comprehensive reporting, and insights into student attendance trends at scale.",
    "problemSolutionBridge": "To replace manual tracking with automated, multi-institution-ready analytics, I built an attendance system that isolates each institution's data and handles report generation and API failures without bringing down the whole platform.",
    "solution": "I architected a modern attendance management system that automates attendance tracking, provides comprehensive analytics, and integrates seamlessly with educational workflows. The system includes secure JWT-based authentication, role-based access control, real-time reporting with Chart.js visualizations, and mobile-responsive design. Built with React, Node.js, Express, and MongoDB for horizontal scalability and fault tolerance.",
    "keyTerms": [
      { "term": "Organization-scoped data isolation", "explanation": "Every query and report is filtered by institution/organization so one school never sees another's data; this supports the project goal of multi-institution deployment on a single platform while keeping compliance and privacy simple." },
      { "term": "MongoDB aggregation pipelines", "explanation": "Analytics and reports are computed on-demand with aggregations so we avoid pre-computed caches going stale; for this project that means admins always see up-to-date attendance and trends without a separate ETL layer." },
      { "term": "Atomic updates (transactions)", "explanation": "Marking attendance or bulk updates run inside MongoDB transactions so partial failures do not leave records half-updated; that directly supports the goal of 95% accuracy and trustworthy reporting." }
    ],
    "failureModes": "API or DB failure: centralized error middleware returns clear status codes and messages so the frontend can show retry or offline cues without crashing. Report generation timeout: long-running reports are isolated so they do not block other requests; connection pooling prevents exhaustion. Invalid or duplicate marks: validation and idempotent-friendly flows reduce double-counting; transactions ensure all-or-nothing updates. Frontend errors: error boundaries keep one broken report view from taking down the dashboard.",
    "impact": "The attendance system has improved tracking accuracy by 95% and reduced administrative time by 70%. Schools using the system report better student engagement and more accurate performance analytics. The platform supports 500+ active users across multiple institutions with comprehensive reporting capabilities, handling 15+ report types with sub-second generation times.",
    "architecture": "The system follows a three-tier architecture: React frontend, Node.js/Express API layer, and MongoDB database. Authentication is handled through JWT tokens with role-based access control. Analytics are computed on-demand using MongoDB aggregation pipelines, ensuring real-time accuracy. File exports (CSV, PDF) are generated server-side to reduce client load. The architecture supports multi-institution deployment through organization-scoped data isolation. MongoDB indexing optimizes query performance for large datasets.",
    "isolation": "Service isolation is achieved through Express route middleware, separating authentication, attendance tracking, and reporting logic. Database operations use MongoDB transactions for atomic updates. Error handling is centralized with custom middleware, preventing cascading failures. File generation is isolated in worker processes to prevent blocking API requests. Client-side state management uses React Context API with error boundaries for component isolation. Database connection pooling prevents connection exhaustion under concurrent load.",
    "tradeoffs": "I chose MongoDB over PostgreSQL because the document model fit varying institution and report shapes and gave us a path to horizontal scaling, trading strict relational integrity for flexibility. I implemented on-demand analytics over pre-computed reports because we needed real-time accuracy as data changed, accepting some query cost. I used Chart.js on the client over server-side charts because interactivity and drill-down were priorities. I selected JWT over sessions so we could scale API servers without a shared session store. I deferred biometrics and automated notifications to ship core tracking and reporting first.",
    "implementationStatus": "Completed (~70%): Core attendance tracking, student management, class organization, analytics dashboard, 15+ report types, role-based access control, and mobile-responsive UI. Deferred: Biometric integration, automated email/SMS notifications, mobile native apps, third-party integrations (SIS systems), and advanced predictive analytics.",
    "potentialExpansion": "Vision includes scaling to 10,000+ users through MongoDB sharding, Redis caching for frequently accessed reports, and microservices extraction for analytics and notifications. Planned containerization with Docker for consistent deployments. Advanced features include AI-powered attendance prediction, automated intervention triggers, and comprehensive parent/guardian portals. Multi-region deployment for global institutions with data replication and compliance features.",
    "technologies": [
      {
        "name": "React.js",
        "category": "Frontend",
        "icon": "react"
      },
      {
        "name": "Node.js",
        "category": "Backend",
        "icon": "nodejs"
      },
      {
        "name": "Express.js",
        "category": "Backend",
        "icon": "express"
      },
      {
        "name": "MongoDB",
        "category": "Database",
        "icon": "mongodb"
      },
      {
        "name": "Mongoose",
        "category": "ODM",
        "icon": "mongoose"
      },
      {
        "name": "JWT",
        "category": "Authentication",
        "icon": "jwt"
      },
      {
        "name": "bcryptjs",
        "category": "Security",
        "icon": "bcrypt"
      },
      {
        "name": "Tailwind CSS",
        "category": "Styling",
        "icon": "tailwind"
      },
      {
        "name": "Chart.js",
        "category": "Visualization",
        "icon": "chartjs"
      }
    ],
    "features": [
      "Secure user authentication using JWT tokens",
      "Comprehensive student management (add, edit, delete, view records)",
      "Daily attendance tracking and management",
      "Class organization and scheduling",
      "Performance analytics with statistics and detailed reports",
      "Responsive design for all devices",
      "Dark mode theme toggle",
      "Role-based access control for different user types"
    ],
    "challenges": [
      "Implementing secure authentication and authorization with JWT tokens",
      "Creating intuitive analytics dashboards with Chart.js visualizations",
      "Optimizing database queries for large datasets with MongoDB indexing",
      "Ensuring data privacy and security compliance with bcrypt password hashing",
      "Building responsive design for various devices with Tailwind CSS",
      "Managing complex state with React Context API for user sessions"
    ],
    "outcomes": [
      "95% improvement in attendance tracking accuracy with automated systems",
      "70% reduction in administrative time through streamlined workflows",
      "Comprehensive analytics and reporting capabilities with 15+ report types",
      "Mobile-responsive design with excellent UX across all devices",
      "Secure role-based access control supporting multiple user types",
      "Production deployment on Netlify and Render with MongoDB database"
    ],
    "metrics": [
      {
        "label": "Accuracy",
        "value": "95%",
        "description": "Improvement in attendance tracking accuracy"
      },
      {
        "label": "Time Saved",
        "value": "70%",
        "description": "Reduction in administrative time"
      },
      {
        "label": "Users",
        "value": "500+",
        "description": "Active users across institutions"
      },
      {
        "label": "Reports",
        "value": "15+",
        "description": "Different report types available"
      }
    ],
    "links": {
      "live": "https://attendance-syst.netlify.app",
      "github": "https://github.com/Ancel-duke"
    },
    "images": {
      "hero": "/assets/projects/attendance.jpg",
      "before": "/assets/projects/attendance.jpg",
      "after": "/assets/projects/attendance.jpg",
      "gallery": [
        "/assets/projects/attendance.jpg"
      ]
    }
  },
  {
    "id": 4,
    "slug": "personal-finance-tracker",
    "title": "Personal Finance Tracker",
    "subtitle": "A modern web application for tracking personal income and expenses with visual analytics",
    "role": "Frontend Developer",
    "timeline": "2 months",
    "year": "2023",
    "status": "Live",
    "description": "A creative frontend experiment exploring modern UI patterns and data visualization techniques. This project demonstrates Vue 3's Composition API, reactive state management, and interactive charting capabilities for personal finance tracking.",
    "problem": "People struggle to track spending habits and understand where their money goes. Traditional spreadsheets are cumbersome and don't provide visual insights. This project explores how modern frontend frameworks can create intuitive, visually engaging financial tracking experiences.",
    "problemSolutionBridge": "To turn raw numbers into clear spending insights, I built a client-side Vue 3 app that keeps calculations and UI in sync and degrades gracefully when storage or rendering fails.",
    "solution": "I built a Vue 3 application with Chart.js for data visualization, using the Composition API for logic reuse and Vue's reactivity system for real-time financial calculations. The project demonstrates modern UI patterns, smooth animations, and responsive design principles.",
    "keyTerms": [
      { "term": "Composition API", "explanation": "In this tracker, reusable logic (totals, category sums) lives in composables so the same calculations drive both the list and the charts; that supports the goal of a single source of truth and a maintainable codebase." },
      { "term": "Reactive state", "explanation": "Income and expenses are reactive so adding or editing a transaction immediately updates totals and pie charts without manual refresh; that keeps the experience instant and aligned with the project's focus on clarity." },
      { "term": "Client-side persistence", "explanation": "Data is stored in localStorage so the app works offline and across sessions; for this project that avoids a backend while making loss of data (e.g. cleared storage) a known failure mode we handle with clear UX." }
    ],
    "failureModes": "LocalStorage full or unavailable: the app checks for quota and write errors and shows a clear message so users know data may not persist. Chart render failure: Chart.js is wrapped so a broken config or missing data does not crash the page; we fall back to a simple table or message. Invalid or missing input: form validation and reactive defaults prevent NaN or empty totals; the UI stays consistent.",
    "impact": "This creative experiment showcases modern frontend development practices, demonstrating Vue 3's capabilities for building interactive, data-driven applications. Users can track spending patterns with visual feedback, exploring how modern UI patterns enhance financial tracking experiences.",
    "technologies": [
      {
        "name": "Vue.js 3",
        "category": "Frontend",
        "icon": "vue"
      },
      {
        "name": "TypeScript",
        "category": "Language",
        "icon": "typescript"
      },
      {
        "name": "Chart.js",
        "category": "Visualization",
        "icon": "chartjs"
      },
      {
        "name": "Tailwind CSS",
        "category": "Styling",
        "icon": "tailwind"
      }
    ],
    "features": [
      "Income and expense tracking",
      "Interactive pie charts for expense breakdown",
      "Category management",
      "Dark/light mode toggle",
      "Responsive design",
      "Local storage persistence"
    ],
    "challenges": [
      "Creating intuitive data visualization",
      "Implementing smooth chart animations",
      "Designing user-friendly expense input forms",
      "Ensuring data persistence across sessions"
    ],
    "outcomes": [
      "Clean, intuitive user interface",
      "Real-time expense tracking",
      "Visual analytics for spending patterns",
      "Mobile-responsive design"
    ],
    "metrics": [
      {
        "label": "Performance",
        "value": "95+",
        "description": "Lighthouse performance score"
      }
    ],
    "links": {
      "live": "https://tracks-finances.netlify.app",
      "github": "https://github.com/Ancel-duke"
    },
    "images": {
      "hero": "/assets/projects/finance-tracker.jpg",
      "before": "/assets/projects/finance-tracker.jpg",
      "after": "/assets/projects/finance-tracker.jpg",
      "gallery": [
        "/assets/projects/finance-tracker.jpg"
      ]
    }
  },
  {
    "id": 5,
    "slug": "fitness-class-scheduler",
    "title": "Fitness Class Scheduler",
    "subtitle": "A modern Angular SSR application for planning weekly fitness classes",
    "role": "Frontend Developer",
    "timeline": "1.5 months",
    "year": "2023",
    "status": "Live",
    "description": "A modern Angular SSR application for planning weekly fitness classes with dark mode, responsive design, and client-side persistence.",
    "problem": "Fitness instructors need an easy way to schedule and manage their weekly classes, with the ability to view schedules in different formats.",
    "problemSolutionBridge": "To give instructors one place to plan and view weekly classes without losing work on refresh, I built an Angular SSR app with client-side persistence and clear error handling.",
    "solution": "I built an Angular 20 application with server-side rendering, featuring drag-and-drop scheduling, dark mode, and local storage persistence.",
    "keyTerms": [
      { "term": "Server-side rendering (SSR)", "explanation": "In this scheduler, the first paint is rendered on the server so the schedule is visible and SEO-friendly before JavaScript runs; that supports the goal of fast, reliable loading for instructors." },
      { "term": "Local storage persistence", "explanation": "Class data is saved in the browser so instructors do not lose work on refresh or close; for this project that avoids a backend while making storage quota a known failure mode we handle with clear messaging." },
      { "term": "Drag-and-drop scheduling", "explanation": "Classes can be reordered or rescheduled via drag-and-drop so the UI matches how instructors think about the week; that supports the goal of an intuitive, low-friction planning experience." }
    ],
    "failureModes": "LocalStorage full or disabled: the app checks and shows a message so instructors know data may not persist. SSR or hydration error: Angular recovers so the client can still interact; we avoid blank screen. Network or API failure: not applicable (client-only); any future sync failure would be isolated and retried.",
    "impact": "Fitness instructors can now easily manage their class schedules with a modern, responsive interface that works on all devices.",
    "technologies": [
      {
        "name": "Angular 20",
        "category": "Frontend",
        "icon": "angular"
      },
      {
        "name": "TypeScript",
        "category": "Language",
        "icon": "typescript"
      },
      {
        "name": "Angular SSR",
        "category": "Frontend",
        "icon": "angular"
      },
      {
        "name": "Tailwind CSS",
        "category": "Styling",
        "icon": "tailwind"
      }
    ],
    "features": [
      "Weekly class scheduling",
      "Drag-and-drop interface",
      "Dark mode toggle",
      "Server-side rendering",
      "Local storage persistence",
      "Responsive design"
    ],
    "challenges": [
      "Implementing drag-and-drop functionality",
      "Optimizing SSR performance",
      "Creating intuitive scheduling interface",
      "Ensuring cross-browser compatibility"
    ],
    "outcomes": [
      "Fast-loading SSR application",
      "Intuitive scheduling interface",
      "Excellent mobile experience",
      "SEO-optimized pages"
    ],
    "metrics": [
      {
        "label": "Load Time",
        "value": "< 1s",
        "description": "Initial page load time"
      },
      {
        "label": "SEO Score",
        "value": "98/100",
        "description": "Google PageSpeed Insights"
      }
    ],
    "links": {
      "live": "https://fitnessss-tracker.netlify.app",
      "github": "https://github.com/Ancel-duke"
    },
    "images": {
      "hero": "/assets/projects/fitness.jpg",
      "before": "/assets/projects/fitness.jpg",
      "after": "/assets/projects/fitness.jpg",
      "gallery": [
        "/assets/projects/fitness.jpg"
      ]
    }
  },
  {
    "id": 6,
    "slug": "habit-tracker",
    "title": "Habit Tracker & Streak Counter",
    "subtitle": "A Progressive Web App for tracking daily habits and building momentum",
    "role": "Frontend Developer",
    "timeline": "2 months",
    "year": "2023",
    "status": "Live",
    "description": "A creative Progressive Web App experiment exploring offline-first design patterns and modern UI interactions. This project demonstrates PWA capabilities, service workers, and engaging visual feedback for habit tracking.",
    "problem": "People struggle to build and maintain positive daily habits. This project explores how modern PWA technologies can create engaging, offline-capable habit tracking experiences with visual motivation and streak mechanics.",
    "problemSolutionBridge": "To make habit tracking work even when the network is unreliable, I built a PWA that runs and persists data offline so users never lose streak or progress.",
    "solution": "I built a React PWA with habit tracking, streak counting, and visual analytics, using a service worker for offline support, LocalStorage for persistence, and modern UI patterns for engaging feedback.",
    "keyTerms": [
      { "term": "Service worker", "explanation": "In this habit tracker, the service worker caches assets and enables offline use so the app loads and works without network; that supports the goal of reliability for daily check-ins." },
      { "term": "Offline-first persistence", "explanation": "Habits and streaks are stored locally and synced when online so users never lose data on spotty connections; for this project that makes the app resilient to network failure." },
      { "term": "Streak calculation", "explanation": "Streaks are computed from stored check-in history so progress is consistent and motivating; that supports the goal of visual momentum and accountability." }
    ],
    "failureModes": "LocalStorage full: we surface a clear message and avoid silent data loss. Service worker update failure: the app still works with cached assets; next load can pick up the new worker. Corrupt or missing data: we validate on load and fall back to empty state so the app does not crash.",
    "impact": "This creative experiment showcases PWA development practices, demonstrating offline-first design, service worker implementation, and modern UI patterns for building engaging productivity applications.",
    "technologies": [
      {
        "name": "React 19",
        "category": "Frontend",
        "icon": "react"
      },
      {
        "name": "PWA",
        "category": "Frontend",
        "icon": "react"
      },
      {
        "name": "Chart.js",
        "category": "Visualization",
        "icon": "chartjs"
      },
      {
        "name": "Tailwind CSS",
        "category": "Styling",
        "icon": "tailwind"
      }
    ],
    "features": [
      "Habit creation and management",
      "Automatic streak calculation",
      "Comprehensive analytics",
      "PWA capabilities",
      "Offline support",
      "Data visualization"
    ],
    "challenges": [
      "Implementing PWA features",
      "Creating engaging streak tracking",
      "Designing intuitive habit management",
      "Ensuring offline functionality"
    ],
    "outcomes": [
      "Fully functional PWA",
      "Engaging habit tracking experience",
      "Visual progress feedback",
      "Offline-first design"
    ],
    "metrics": [
      {
        "label": "PWA Score",
        "value": "100/100",
        "description": "Lighthouse PWA score"
      },
      {
        "label": "Offline Support",
        "value": "100%",
        "description": "Full offline functionality"
      }
    ],
    "links": {
      "live": "https://habitss-tracker.netlify.app",
      "github": "https://github.com/Ancel-duke"
    },
    "images": {
      "hero": "/assets/projects/habit-tracker.jpg",
      "before": "/assets/projects/habit-tracker.jpg",
      "after": "/assets/projects/habit-tracker.jpg",
      "gallery": [
        "/assets/projects/habit-tracker.jpg"
      ]
    }
  },
  {
    "id": 7,
    "slug": "event-countdown-timer",
    "title": "Event Countdown Timer",
    "subtitle": "A feature-rich countdown timer for various life events",
    "role": "Frontend Developer",
    "timeline": "1 month",
    "year": "2022",
    "status": "Live",
    "description": "A feature-rich countdown timer web application for creating and managing multiple countdowns for various life events with recurring events and smart notifications.",
    "problem": "People need a simple way to track countdowns to important events like birthdays, anniversaries, and deadlines.",
    "problemSolutionBridge": "To keep countdowns simple and always available, I built a vanilla JS app with local persistence and clear fallbacks when storage or notifications fail.",
    "solution": "I built a vanilla JavaScript application with multiple countdown views, recurring events, and smart notifications.",
    "keyTerms": [
      { "term": "Recurring events", "explanation": "Countdowns can repeat yearly (or at other intervals) so users set once and keep getting reminded; that supports the goal of low-friction tracking for life events." },
      { "term": "Local storage persistence", "explanation": "Events are saved in the browser so they survive refresh and return visits; for this project that avoids a backend while handling quota errors with clear UX." },
      { "term": "Smart notifications", "explanation": "The app uses browser APIs to notify when a countdown reaches zero so users do not miss the moment; that supports the goal of timely, reliable reminders." }
    ],
    "failureModes": "LocalStorage full or blocked: we detect and inform the user so they know events may not persist. Notification permission denied: countdowns still work; we do not block the app. Timer drift or tab in background: we recalculate on focus so displayed time stays accurate.",
    "impact": "Users can now easily track multiple countdowns with automatic yearly repetition and visual customization.",
    "technologies": [
      {
        "name": "Vanilla JavaScript",
        "category": "Language",
        "icon": "javascript"
      },
      {
        "name": "HTML5",
        "category": "Frontend",
        "icon": "html"
      },
      {
        "name": "CSS3",
        "category": "Styling",
        "icon": "css"
      },
      {
        "name": "Canvas API",
        "category": "Frontend",
        "icon": "canvas"
      }
    ],
    "features": [
      "Multiple countdown views",
      "Recurring events",
      "Visual customization",
      "Smart notifications",
      "Local storage persistence",
      "URL sharing"
    ],
    "challenges": [
      "Implementing accurate countdown calculations",
      "Creating smooth animations",
      "Handling timezone differences",
      "Designing intuitive event management"
    ],
    "outcomes": [
      "Lightweight, fast application",
      "Intuitive event management",
      "Beautiful visual design",
      "Cross-browser compatibility"
    ],
    "metrics": [
      {
        "label": "Bundle Size",
        "value": "< 50KB",
        "description": "Total application size"
      },
      {
        "label": "Load Time",
        "value": "< 500ms",
        "description": "Initial load time"
      }
    ],
    "links": {
      "live": "https://event-countdowns.netlify.app",
      "github": "https://github.com/Ancel-duke"
    },
    "images": {
      "hero": "/assets/projects/events.jpg",
      "before": "/assets/projects/events.jpg",
      "after": "/assets/projects/events.jpg",
      "gallery": [
        "/assets/projects/events.jpg"
      ]
    }
  },
  {
    "id": 8,
    "slug": "travelogue",
    "title": "Travelogue - Travel Storytelling Website",
    "subtitle": "A comprehensive travel platform with interactive world maps",
    "role": "Frontend Developer",
    "timeline": "2.5 months",
    "year": "2023",
    "status": "Live",
    "description": "A comprehensive travel platform featuring interactive world maps, travel stories, destination exploration, and responsive design for travel enthusiasts.",
    "problem": "Travel enthusiasts need a platform to share their experiences and discover new destinations through interactive maps and stories.",
    "problemSolutionBridge": "To combine maps and stories in one place, I built a React app with Leaflet so content loads progressively and map or API failures do not break the rest of the experience.",
    "solution": "I built a React application with Leaflet.js integration, featuring interactive world maps, travel stories, and destination exploration.",
    "keyTerms": [
      { "term": "Leaflet.js / OpenStreetMap", "explanation": "In this travel platform, maps are rendered with Leaflet and OSM so destinations are explorable without a paid map API; that supports the goal of an interactive, shareable travel experience." },
      { "term": "Masonry layout", "explanation": "Stories and photos use a masonry grid so varying content heights look natural; that supports the goal of a blog-like, visual discovery experience." },
      { "term": "Theme persistence", "explanation": "Dark/light theme is stored in LocalStorage so user preference survives refresh; for this project that keeps the reading experience consistent across visits." }
    ],
    "failureModes": "Map tile or API failure: the map degrades to a placeholder or message so the rest of the page (stories, nav) still works. Image load failure: we use fallbacks or alt content so the layout does not break. LocalStorage full: theme may reset on next visit; we do not block rendering.",
    "impact": "Users can now explore destinations through interactive maps and read detailed travel experiences from other travelers.",
    "technologies": [
      {
        "name": "React 18",
        "category": "Frontend",
        "icon": "react"
      },
      {
        "name": "Leaflet.js",
        "category": "Maps",
        "icon": "leaflet"
      },
      {
        "name": "OpenStreetMap",
        "category": "Maps",
        "icon": "map"
      },
      {
        "name": "Tailwind CSS",
        "category": "Styling",
        "icon": "tailwind"
      }
    ],
    "features": [
      "Interactive world map",
      "Travel story sharing",
      "Destination exploration",
      "Photo galleries",
      "Dark/light mode",
      "Responsive design"
    ],
    "challenges": [
      "Integrating interactive maps",
      "Optimizing map performance",
      "Creating engaging travel stories",
      "Implementing smooth map interactions"
    ],
    "outcomes": [
      "Engaging interactive maps",
      "Beautiful travel stories",
      "Fast map loading",
      "Mobile-optimized experience"
    ],
    "metrics": [
      {
        "label": "Map Load Time",
        "value": "< 2s",
        "description": "Initial map rendering"
      }
    ],
    "links": {
      "live": "https://travelslogue.netlify.app",
      "github": "https://github.com/Ancel-duke"
    },
    "images": {
      "hero": "/assets/projects/travel.jpg",
      "before": "/assets/projects/travel.jpg",
      "after": "/assets/projects/travel.jpg",
      "gallery": [
        "/assets/projects/travel.jpg"
      ]
    }
  },
  {
    "id": 9,
    "slug": "rasoha-academy",
    "title": "Rasoha Academy - School Website",
    "subtitle": "A modern, responsive website for a private school in Kenya",
    "role": "Full-Stack Developer",
    "timeline": "1 month",
    "year": "2024",
    "status": "Live",
    "description": "A modern, responsive website for a private school in Narok, Kenya, providing comprehensive information about programs, events, and resources for students and parents.",
    "problem": "The school needed a professional online presence to showcase their programs and provide information to students and parents.",
    "problemSolutionBridge": "To give the school one reliable, fast site that works even on slow connections, I built a React PWA with clear structure and offline fallbacks.",
    "solution": "I built a comprehensive React website with PWA capabilities, featuring school information, events, photo galleries, and contact details.",
    "keyTerms": [
      { "term": "PWA (Progressive Web App)", "explanation": "Rasoha Academy's site can be installed and used offline so parents and students in low-connectivity areas can still access key info; that supports the goal of reliable access for the community." },
      { "term": "SEO optimization", "explanation": "Meta tags, structure, and performance are tuned so the school appears in local and program-related search; that supports the goal of discoverability for prospective families." },
      { "term": "Responsive and accessible design", "explanation": "Layout and components work across devices and respect accessibility so all visitors can use the site; that supports the goal of an inclusive school presence." }
    ],
    "failureModes": "Offline or slow network: the service worker serves cached pages so key info remains available. Image or asset failure: we use fallbacks and alt text so the page does not break. Form or contact failure: we show clear errors and retry options so the school does not lose leads.",
    "impact": "The school now has a professional online presence that effectively communicates with students, parents, and the community.",
    "technologies": [
      {
        "name": "React 19.1.1",
        "category": "Frontend",
        "icon": "react"
      },
      {
        "name": "Tailwind CSS",
        "category": "Styling",
        "icon": "tailwind"
      },
      {
        "name": "PWA",
        "category": "Frontend",
        "icon": "react"
      },
      {
        "name": "React Icons",
        "category": "Frontend",
        "icon": "react"
      }
    ],
    "features": [
      "School information pages",
      "Events calendar",
      "Photo galleries",
      "Contact information",
      "PWA capabilities",
      "SEO optimization"
    ],
    "challenges": [
      "Creating engaging school content",
      "Implementing PWA features",
      "Optimizing for mobile devices",
      "Ensuring accessibility compliance"
    ],
    "outcomes": [
      "Professional school website",
      "Excellent mobile experience",
      "Fast loading times",
      "SEO-optimized content"
    ],
    "metrics": [
      {
        "label": "Performance",
        "value": "95+",
        "description": "Lighthouse performance score"
      },
      {
        "label": "Accessibility",
        "value": "98/100",
        "description": "WCAG compliance score"
      }
    ],
    "links": {
      "live": "https://rasoha.netlify.app",
      "github": "https://github.com/Ancel-duke"
    },
    "images": {
      "hero": "/assets/projects/rasoha.jpg",
      "before": "/assets/projects/rasoha.jpg",
      "after": "/assets/projects/rasoha.jpg",
      "gallery": [
        "/assets/projects/rasoha.jpg"
      ]
    }
  }
  ,
  {
    "id": 10,
    "slug": "banking-system",
    "title": "Banking System",
    "subtitle": "Console-based banking system demonstrating OOP principles in Java",
    "role": "Backend / Java Developer",
    "timeline": "1 week",
    "year": "2025",
    "status": "Open Source",
    "description": "A simple, console-based Banking System implemented in pure Java to demonstrate core OOP principles (Encapsulation, Inheritance, Abstraction, Polymorphism). Includes customer management, savings/checking accounts, deposits, withdrawals, transfers, and transaction logs.",
    "problem": "Showcase solid object-oriented design and problem-solving skills without relying on external frameworks or databases.",
    "problemSolutionBridge": "To demonstrate clean OOP and domain modeling, I designed a small banking core where accounts, transactions, and the bank are clearly separated and easy to reason about.",
    "solution": "I designed an extensible domain model with an abstract Account base class and concrete Savings/Checking accounts, a Bank aggregate to manage customers/accounts, and transaction records capturing all operations.",
    "keyTerms": [
      { "term": "Encapsulation and polymorphism", "explanation": "Account types hide internal state and expose a consistent interface so the Bank can treat savings and checking uniformly; that supports the goal of clear, maintainable OOP." },
      { "term": "Domain model / aggregate", "explanation": "The Bank aggregate owns customers and accounts and enforces invariants (e.g. no negative balance) so the project demonstrates how to keep business rules in one place." },
      { "term": "Transaction records", "explanation": "Every deposit, withdrawal, and transfer is recorded so we have an audit trail and can reason about correctness; that supports the goal of a credible, educational banking example." }
    ],
    "failureModes": "Invalid input (e.g. negative amount): the domain model rejects or validates so we never apply invalid operations. No external I/O: the app is console-only and in-memory so there are no network or storage failures; failure handling is demonstrated through validation and clear error messages.",
    "impact": "Clear demonstration of OOP fundamentals, clean architecture, and maintainable code suitable for technical interviews and backend design discussions.",
    "technologies": [
      { "name": "Java 17+", "category": "Language", "icon": "java" },
      { "name": "OOP", "category": "Concept", "icon": "oop" },
      { "name": "Maven", "category": "Build", "icon": "maven" },
      { "name": "Gradle", "category": "Build", "icon": "gradle" }
    ],
    "features": [
      "Create customers and open savings/checking accounts",
      "Deposit, withdraw, transfer between accounts",
      "View balances and transaction history",
      "Encapsulation via private fields and public methods",
      "Inheritance and polymorphism across account types",
      "Abstraction with abstract base class for shared behavior"
    ],
    "challenges": [
      "Designing a clean, extensible account hierarchy",
      "Ensuring correctness of monetary operations",
      "Maintaining clear separation of concerns"
    ],
    "outcomes": [
      "Readable and testable code showcasing core OOP",
      "Lightweight console interface requiring no external services"
    ],
    "metrics": [
      { "label": "Frameworks", "value": "0", "description": "Pure Java only" }
    ],
    "links": {
      "live": "",
      "github": "https://github.com/Ancel-duke/banking"
    },
    "images": {
      "hero": "/assets/projects/bank.jpg",
      "before": "/assets/projects/bank.jpg",
      "after": "/assets/projects/bank.jpg",
      "gallery": ["/assets/projects/bank.jpg"]
    }
  },
  {
    "id": 12,
    "slug": "educhain",
    "title": "EduChain - Blockchain Certificate Management",
    "subtitle": "Full-stack Web3 application for issuing verifiable academic certificates as NFTs",
    "role": "Full-Stack Software Engineer",
    "timeline": "3 months",
    "year": "2026",
    "status": "Live",
    "description": "EduChain is a resilient, decentralized certificate management system architected on Web3 principles, issuing verifiable academic certificates as ERC721 NFTs on the Ethereum blockchain. The platform enables educational institutions to issue tamper-proof, blockchain-verified certificates while providing students with permanent, verifiable proof of achievements through hybrid storage (MongoDB + IPFS + Blockchain).",
    "problem": "Traditional paper certificates and digital PDFs are easily forged, difficult to verify, and can be lost or damaged. Educational institutions need a secure, decentralized solution to issue and verify academic credentials that cannot be tampered with and remain permanently accessible. Students require a way to prove credentials without relying on centralized authorities, with instant verification capabilities.",
    "problemSolutionBridge": "To make credentials tamper-proof and verifiable without a central authority, I designed a hybrid system that keeps issuance fast and cheap while putting permanent proof on-chain.",
    "solution": "I architected EduChain as a blockchain-based certificate management system leveraging ERC721 NFT standards to create immutable, verifiable certificates. Each certificate is permanently stored on the Ethereum blockchain with metadata on IPFS, ensuring tamper-proof verification and permanent accessibility. The platform includes owner-only minting with OpenZeppelin audited patterns, non-transferable NFTs to prevent trading, and comprehensive verification features with dual storage architecture for optimal performance.",
    "keyTerms": [
      { "term": "ERC721 NFT minting", "explanation": "In EduChain each certificate is a unique token on Ethereum; minting is owner-only and non-transferable so the credential is tied to the issuer and cannot be sold, supporting the goal of verifiable academic proof." },
      { "term": "IPFS decentralized storage", "explanation": "Certificate metadata (name, date, institution) is stored on IPFS so it is content-addressed and durable without a central server; for this project that keeps verification data available even if our backend is down." },
      { "term": "ReentrancyGuard", "explanation": "The smart contract uses OpenZeppelin's ReentrancyGuard so a single mint or transfer cannot be re-entered mid-execution; that protects the project goal of correct, one-to-one certificate issuance." }
    ],
    "failureModes": "Wallet disconnect or reject: the frontend handles connection loss and user rejection without crashing; issuance state is recoverable. IPFS pin failure: backend retries and returns clear errors so issuers know if metadata did not pin. RPC or gas spike: read-only verification still works; minting can be retried. Smart contract revert: errors are surfaced so the UI can show retry or support; MongoDB is not updated until on-chain success so we avoid inconsistent state.",
    "impact": "EduChain provides a secure, decentralized solution for certificate management with instant verification capabilities. The platform ensures certificates are permanently accessible, tamper-proof, and easily verifiable by anyone with the certificate token ID. The system uses OpenZeppelin audited patterns for security, includes dual storage (MongoDB for queries, IPFS for metadata, Blockchain for verification), and demonstrates production-grade Web3 architecture with comprehensive error handling.",
    "architecture": "EduChain follows a hybrid storage architecture: React 19 frontend with RainbowKit for wallet connection, Node.js/Express backend for certificate management, MongoDB for efficient querying and batch operations, IPFS (via Pinata API) for decentralized metadata storage, and Ethereum blockchain (Sepolia testnet) for immutable certificate verification. Smart contracts use OpenZeppelin v5 ERC721 standard with ReentrancyGuard protection. The architecture separates concerns: frontend handles wallet interactions, backend manages IPFS uploads and MongoDB operations, and blockchain provides permanent verification.",
    "isolation": "Service isolation is achieved through separate layers: frontend wallet interactions are isolated from backend API calls, preventing wallet failures from affecting certificate queries. IPFS operations are handled asynchronously, preventing blocking of API requests. Smart contract interactions use read-only calls where possible, reducing gas costs. Error handling is centralized with custom exception handlers, preventing cascading failures. Database operations use MongoDB transactions for atomic batch operations. Frontend error boundaries isolate Web3 interaction failures, maintaining application stability.",
    "tradeoffs": "I chose hybrid storage (MongoDB + IPFS + Blockchain) over pure blockchain because we needed fast queries and low latency for issuance while keeping verification on-chain; MongoDB for reads, IPFS for metadata, blockchain for proof. I selected the ERC721 standard over custom contracts for interoperability and tooling, trading some customization for ecosystem compatibility. I used OpenZeppelin audited patterns over custom security because battle-tested code reduced risk for certificate issuance. I implemented non-transferable NFTs to prevent certificate trading and keep focus on verification. I deferred multi-chain support to focus on Ethereum first, with Polygon/Arbitrum planned for later.",
    "implementationStatus": "Completed (~75%): Core certificate minting, IPFS integration, wallet-based viewing, public verification, batch management, smart contract deployment, and production deployment. Deferred: Multi-chain support (Polygon, Arbitrum), certificate revocation mechanism, advanced verification features, mobile wallet support, and batch minting optimizations.",
    "potentialExpansion": "Vision includes multi-chain deployment (Polygon, Arbitrum) for lower gas costs, certificate revocation mechanism for edge cases, advanced verification with QR codes, and mobile wallet support. Planned scaling through IPFS pinning services, MongoDB sharding for large institutions, and CDN integration for metadata delivery. Enterprise features include institution-specific smart contracts, automated certificate issuance workflows, and comprehensive audit trails.",
    "technologies": [
      {
        "name": "React 19",
        "category": "Frontend",
        "icon": "react"
      },
      {
        "name": "Tailwind CSS",
        "category": "Styling",
        "icon": "tailwind"
      },
      {
        "name": "RainbowKit",
        "category": "Frontend",
        "icon": "web3"
      },
      {
        "name": "Wagmi",
        "category": "Frontend",
        "icon": "web3"
      },
      {
        "name": "ethers.js",
        "category": "Frontend",
        "icon": "ethereum"
      },
      {
        "name": "Node.js",
        "category": "Backend",
        "icon": "nodejs"
      },
      {
        "name": "Express.js",
        "category": "Backend",
        "icon": "express"
      },
      {
        "name": "MongoDB",
        "category": "Database",
        "icon": "mongodb"
      },
      {
        "name": "Mongoose",
        "category": "ODM",
        "icon": "mongoose"
      },
      {
        "name": "Solidity",
        "category": "Blockchain",
        "icon": "solidity"
      },
      {
        "name": "Hardhat",
        "category": "Blockchain",
        "icon": "hardhat"
      },
      {
        "name": "IPFS",
        "category": "Storage",
        "icon": "ipfs"
      }
    ],
    "features": [
      "Secure certificate minting with owner-only access control",
      "IPFS integration for decentralized metadata storage",
      "Wallet-based certificate viewing for students",
      "Public certificate verification using token IDs",
      "Batch management through MongoDB",
      "Clean grayscale UI design",
      "Real-time blockchain state updates",
      "Non-transferable NFTs to prevent certificate trading"
    ],
    "challenges": [
      "Integrating multiple Web3 libraries (RainbowKit, Wagmi, ethers.js v6) with proper async handling",
      "Coordinating frontend, backend, and blockchain interactions seamlessly",
      "Implementing automatic metadata upload and retrieval from IPFS via Pinata API",
      "Resolving Node.js version conflicts and peer dependency issues in production",
      "Fixing ethers.js v6 async signer issues and implementing proper contract interactions",
      "Configuring multi-network support with proper chain switching and provider management",
      "Designing secure smart contracts with OpenZeppelin v5 and ReentrancyGuard protection"
    ],
    "outcomes": [
      "Fully functional Web3 application with all core features implemented and tested",
      "Production deployment on Netlify (frontend), Render (backend), and Sepolia testnet (smart contracts)",
      "Secure smart contract with owner-only minting and ReentrancyGuard protection",
      "Dual storage system with MongoDB for queries, IPFS for metadata, and Blockchain for verification",
      "Comprehensive error handling and loading states for all Web3 interactions",
      "Clean, professional UI with excellent user experience and wallet integration"
    ],
    "metrics": [
      {
        "label": "Smart Contract",
        "value": "ERC721-compliant",
        "description": "OpenZeppelin audited patterns"
      },
      {
        "label": "API Endpoints",
        "value": "5 RESTful",
        "description": "Comprehensive error handling"
      },
      {
        "label": "Security",
        "value": "Owner-only",
        "description": "ReentrancyGuard protection"
      },
      {
        "label": "Storage",
        "value": "Dual system",
        "description": "MongoDB + IPFS + Blockchain"
      }
    ],
    "links": {
      "live": "https://educhainn.netlify.app",
      "github": "https://github.com/Ancel-duke/EduChain"
    },
    "images": {
      "hero": "/assets/projects/EduChain.jpg",
      "before": "/assets/projects/EduChain.jpg",
      "after": "/assets/projects/EduChain.jpg",
      "gallery": [
        "/assets/projects/EduChain.jpg"
      ]
    }
  },
  {
    "id": 11,
    "slug": "ledgerx",
    "title": "LedgerX â€” Secure, Multi-Tenant Financial Platform",
    "subtitle": "Production-grade invoicing, payments, double-entry ledger, audit, fraud detection, and diagnostics",
    "role": "Full-Stack Software Engineer",
    "timeline": "Ongoing",
    "year": "2026",
    "status": "Live",
    "description": "LedgerX is a production-grade, multi-tenant financial platform designed to handle invoicing, payments, accounting (double-entry ledger), audit/compliance, fraud detection, and system diagnostics in a single, cohesive system.",
    "problem": "Most small-to-mid business financial tools suffer from weak multi-tenancy boundaries, poor auditability and compliance trails, payments tightly coupled to providers, no real fraud model beyond manual review, little observability when things degrade, and frontends that break under real usage. LedgerX was designed to solve these problems holistically.",
    "problemSolutionBridge": "To fix weak boundaries and poor auditability, I designed LedgerX so every request is org-scoped, every important action is an event, and payments and diagnostics fail in controlled ways without corrupting the ledger.",
    "solution": "I built LedgerX around six non-negotiables: strong multi-tenant isolation (every request and query organization-scoped), auditability by default (important actions are events and recorded), financial correctness (true double-entry ledger with append-only hash chain), resilience under failure (circuit breakers, graceful degradation), operational visibility (health, metrics, diagnostics, feature flags, controlled remediation), and security that earns respect (JWT + token versioning, rate limiting, role-restricted audit/diagnostics).",
    "keyTerms": [
      { "term": "Idempotency (payment intents)", "explanation": "In LedgerX each payment intent is idempotent so duplicate webhooks or retries do not double-charge; that directly supports the goal of financial correctness and safe reconciliation with Stripe and M-Pesa." },
      { "term": "Double-entry ledger with hash chain", "explanation": "Every financial movement is a balanced ledger entry in an append-only hash chain so we can detect tampering and reconcile; that supports auditability and compliance for the platform." },
      { "term": "Circuit breakers", "explanation": "Stripe and M-Pesa adapters sit behind circuit breakers so when a provider is down or slow we fail fast and degrade gracefully instead of blocking or corrupting ledger state." }
    ],
    "failureModes": "Payment provider down: circuit breakers open so we do not block requests; we return clear errors and can retry or queue when the provider recovers. Webhook duplicate or replay: idempotent handling ensures we do not double-post to the ledger or double-fulfil an intent. Database or process crash: PostgreSQL transactions and append-only ledger keep data consistent; we can recover and replay from events where needed. Unauthorized access: JWT, token versioning, and role-restricted audit/diagnostics limit blast radius and are audited.",
    "impact": "LedgerX demonstrates senior-level backend architecture, security-first thinking, event-driven system design, fintech-grade data integrity, and operational maturity beyond CRUD. It is designed to be read, reviewed, and respected by experienced engineers.",
    "architecture": "Backend: NestJS, single process. PostgreSQL (Prisma) for core transactional and compliance data; MongoDB for activity logs (high-volume, flexible schema). Domain event bus (in-process) for PaymentCompleted, LedgerTransactionPosted, InvoiceOverdue, DiagnosticsRemediationExecutedâ€”powering audit, fraud, and diagnostics. Stripe and M-Pesa adapters behind circuit breakers; idempotent payment intents; verified webhooks with raw body. Double-entry ledger with append-only hash chain. Frontend: Next.js 14 App Router, React 18, TanStack Query, role-gated navigation, org switcher. Deployed on Render (backend) and Netlify (frontend).",
    "isolation": "Organization as isolation boundary: all business data is organization-scoped. UserOrganization and Role (ADMIN, MANAGER, MEMBER) per org. Org-scoped queries and guards on every endpoint. Fraud signals and risk aggregation per org. Diagnostics and remediation audited. No DB-per-tenant; shared schema with org-scoped queries.",
    "tradeoffs": "I intentionally avoided Docker to reflect environments where containerization is not available, and I chose E2E tests over exhaustive unit tests for real system confidence. I kept fraud rules deterministic rather than ML-heavy so behavior is auditable and predictable. I focused on operational correctness over UI polish. I used a synchronous in-process event bus instead of an out-of-process queue to reduce moving parts and keep the system understandable; single region/process. These decisions are documented in the repo.",
    "implementationStatus": "Production-capable multi-tenant fintech: auth (JWT + refresh, token versioning), org-scoped CRUD, payments (Stripe/M-Pesa), double-entry ledger, domain events, audit/compliance, fraud signals and aggregation, diagnostics (snapshots, reports, feature flags, remediation). E2E coverage is smoke-level; no built-in queue or horizontal scaling.",
    "potentialExpansion": "Documented limitations: single region/process, synchronous event bus, MongoDB for activity only, no built-in queue. Path to extend: add queue, more E2E, horizontal scaling. LLM summarization for diagnostics is feature-flagged and optional.",
    "technologies": [
      {
        "name": "Next.js 14",
        "category": "Frontend",
        "icon": "nextjs"
      },
      {
        "name": "React 18",
        "category": "Frontend",
        "icon": "react"
      },
      {
        "name": "TypeScript",
        "category": "Language",
        "icon": "typescript"
      },
      {
        "name": "NestJS",
        "category": "Backend",
        "icon": "nestjs"
      },
      {
        "name": "PostgreSQL",
        "category": "Database",
        "icon": "postgresql"
      },
      {
        "name": "Prisma",
        "category": "ORM",
        "icon": "prisma"
      },
      {
        "name": "MongoDB",
        "category": "Database",
        "icon": "mongodb"
      },
      {
        "name": "Mongoose",
        "category": "ODM",
        "icon": "mongoose"
      },
      {
        "name": "JWT",
        "category": "Authentication",
        "icon": "jwt"
      },
      {
        "name": "Passport.js",
        "category": "Authentication",
        "icon": "passport"
      },
      {
        "name": "TanStack Query",
        "category": "State Management",
        "icon": "reactquery"
      },
      {
        "name": "Recharts",
        "category": "Visualization",
        "icon": "recharts"
      },
      {
        "name": "Tailwind CSS",
        "category": "Styling",
        "icon": "tailwind"
      },
      {
        "name": "Axios",
        "category": "HTTP Client",
        "icon": "axios"
      }
    ],
    "features": [
      "Strong multi-tenant isolation with organization-scoped queries and role-based access (ADMIN, MANAGER, MEMBER)",
      "Event-driven core: domain event bus for audit, fraud, and diagnostics",
      "Double-entry ledger with append-only hash chain for financial correctness",
      "Stripe and M-Pesa payment adapters with idempotent intents and verified webhooks",
      "Fraud detection: signals from domain events, org-level risk aggregation, policy enforcement",
      "Diagnostics and self-protection: health, metrics, snapshots, feature flags, controlled remediation",
      "JWT + refresh tokens, token versioning, rate limiting, role-restricted audit/diagnostics",
      "Next.js 14 App Router frontend with org switcher and responsive dashboard"
    ],
    "challenges": [
      "Enforcing multi-tenant isolation at every API and query boundary",
      "Designing domain event bus and subscribers for audit, fraud, and diagnostics without coupling",
      "Implementing double-entry ledger and hash chain with atomic posts",
      "Webhook signature verification with raw body for Stripe and M-Pesa",
      "Circuit breakers and graceful degradation when providers fail",
      "Diagnostics and remediation actions that are audited and safe"
    ],
    "outcomes": [
      "Production-grade multi-tenant fintech with event-driven architecture",
      "Auditability by default; financial correctness via double-entry and hash chain",
      "Fraud model and risk enforcement built into the core workflow",
      "Operational visibility: health, metrics, diagnostics, feature flags, remediation",
      "Security by design: JWT, token versioning, rate limiting, secret redaction",
      "Deployed on Render (backend) and Netlify (frontend); live and GitHub retained"
    ],
    "metrics": [
      { "label": "Multi-Tenancy", "value": "Org-scoped", "description": "Every request and query organization-scoped" },
      { "label": "Ledger", "value": "Double-entry", "description": "Append-only hash chain for integrity" },
      { "label": "Payments", "value": "Stripe + M-Pesa", "description": "Adapters behind circuit breakers" },
      { "label": "Observability", "value": "Health + Metrics", "description": "Diagnostics, feature flags, remediation" }
    ],
    "links": {
      "live": "https://ledgerxx.netlify.app/auth/login",
      "github": "https://github.com/Ancel-duke/LedgerX",
      "docs": "https://github.com/Ancel-duke/LedgerX/blob/main/ARCHITECTURE.md"
    },
    "images": {
      "hero": "/assets/projects/LedgerX.jpg",
      "before": "/assets/projects/LedgerX.jpg",
      "after": "/assets/projects/LedgerX2.jpg",
      "gallery": [
        "/assets/projects/LedgerX.jpg",
        "/assets/projects/LedgerX2.jpg"
      ]
    }
  },
  {
    "id": 13,
    "slug": "opsflow",
    "title": "OpsFlow - Incident & Operations Management Platform",
    "subtitle": "Building a production-ready incident and workflow management platform for engineering teams",
    "role": "Full-Stack Software Engineer",
    "timeline": "4 months",
    "year": "2026",
    "status": "Completed",
    "description": "OpsFlow is a production-ready incident and operations management platform architected for engineering teams, combining incident response, workflow management, task coordination, and knowledge sharing into a single secure team-based system. The platform features dual-database architecture (PostgreSQL + MongoDB), real-time WebSocket updates, and team-based multi-tenancy with 50+ API endpoints.",
    "problem": "Engineering and operations teams rely on multiple disconnected tools to manage incidents, workflows, and documentation, leading to poor incident visibility, delayed response times, fragmented operational knowledge, weak accountability, and difficulty scaling workflows as teams grow. Existing solutions are either too expensive or lack the integration needed for unified operations management.",
    "problemSolutionBridge": "To unify incidents, workflows, and knowledge in one place without expensive infra, I built OpsFlow with team-scoped data and real-time updates so failures in one area do not take down the rest.",
    "solution": "I architected OpsFlow as a unified operations platform enabling teams to manage the full incident lifecycle with SLA tracking, coordinate response workflows and tasks in real-time, maintain a searchable team-scoped knowledge base, enforce role-based and team-based access control, and monitor operational health through a centralized dashboard. The system uses dual-database architecture (PostgreSQL for transactions, MongoDB for event logs) and WebSocket-powered real-time updates without requiring paid infrastructure.",
    "keyTerms": [
      { "term": "Dual-database architecture", "explanation": "OpsFlow uses PostgreSQL for ACID incident and workflow data and MongoDB for high-volume event logs; that supports the project goal of both reliable state and cheap, flexible event history without a single bottleneck." },
      { "term": "On-demand SLA calculation", "explanation": "SLA and breach detection run during API requests instead of background jobs so we could ship without a queue or workers; for this project that traded some efficiency for simpler, free-tier-friendly infra." },
      { "term": "Team-scoped multi-tenancy", "explanation": "Every query is filtered by team so one team never sees another's incidents or docs; that supports secure, multi-tenant operations management on a single deployment." }
    ],
    "failureModes": "PostgreSQL or MongoDB down: the app fails clearly for affected operations; WebSocket and API are isolated so a DB blip does not take down the whole process. WebSocket disconnect: clients reconnect and refetch so they do not miss updates. Long-running report or export: request timeouts and async patterns prevent one heavy operation from blocking others. Unauthorized access: RBAC and team-scoped queries enforce isolation; audit trails record who did what.",
    "impact": "Production-ready system with 50+ API endpoints and real-time incident updates without paid infrastructure. Secure team-based multi-tenant architecture with complete data isolation, fully documented setup and deployment guides, and responsive UI across mobile, tablet, and desktop. Demonstrates enterprise-grade backend and system design skills with real-world SaaS architecture, security awareness, and proven ability to build production-ready systems under infrastructure constraints.",
    "architecture": "OpsFlow follows a dual-database architecture: PostgreSQL (via Prisma ORM) for structured relational data (incidents, workflows, teams) and MongoDB for append-only event logs and timelines. The backend uses NestJS modular architecture with feature-based modules. The frontend uses Next.js 14 with TypeScript for type safety. Real-time updates are handled through WebSocket connections (Socket.IO) without background workers, computing SLA calculations and breach detection on-demand during API requests. Multi-tenant isolation is enforced at the database query level with team-scoped filtering.",
    "isolation": "Service isolation is achieved through NestJS modules, separating incident management, workflow coordination, and knowledge base. Database operations use PostgreSQL transactions for atomic updates and MongoDB for isolated event logging. WebSocket handlers are isolated from API routes, preventing real-time failures from affecting REST endpoints. Error handling is centralized with exception filters, preventing cascading failures. Team-level data isolation is enforced at every database query, ensuring complete multi-tenant security. Frontend error boundaries isolate component failures, maintaining application stability.",
    "tradeoffs": "I chose a dual-database architecture (PostgreSQL + MongoDB) over a single database because we needed ACID for incidents and workflows and a flexible store for high-volume event logs. I implemented on-demand SLA calculations over scheduled jobs to avoid paid workers on the free tier, trading some efficiency for cost. I used WebSockets for real-time updates without Redis pub-sub so we could ship with one server and add scale later. I selected Prisma for type safety and migrations over raw SQL. I deferred automated incident routing and advanced analytics to focus on core operations management.",
    "implementationStatus": "Completed (~75%): Core incident management, workflow coordination, knowledge base, team-based multi-tenancy, role-based access control, real-time WebSocket updates, SLA tracking, and audit trails. Deferred: Advanced analytics and reporting, integration with external monitoring tools, mobile native apps, enhanced notification system, and automated incident response workflows.",
    "potentialExpansion": "Vision includes scaling to 1,000+ teams through PostgreSQL read replicas, Redis pub-sub for WebSocket message distribution, and microservices extraction for analytics and notifications. Planned containerization with Docker and Kubernetes for orchestration. Advanced features include AI-powered incident prediction, automated response workflows, integration with PagerDuty/Slack, and comprehensive operational dashboards. Enterprise features include SSO integration, advanced permissions, and white-label customization.",
    "technologies": [
      {
        "name": "NestJS",
        "category": "Backend",
        "icon": "nestjs"
      },
      {
        "name": "Next.js 14",
        "category": "Frontend",
        "icon": "nextjs"
      },
      {
        "name": "TypeScript",
        "category": "Language",
        "icon": "typescript"
      },
      {
        "name": "PostgreSQL",
        "category": "Database",
        "icon": "postgresql"
      },
      {
        "name": "MongoDB",
        "category": "Database",
        "icon": "mongodb"
      },
      {
        "name": "Prisma",
        "category": "ORM",
        "icon": "prisma"
      },
      {
        "name": "WebSockets",
        "category": "Real-time",
        "icon": "socketio"
      },
      {
        "name": "JWT",
        "category": "Authentication",
        "icon": "jwt"
      },
      {
        "name": "RBAC",
        "category": "Security",
        "icon": "security"
      },
      {
        "name": "Tailwind CSS",
        "category": "Styling",
        "icon": "tailwind"
      }
    ],
    "features": [
      "Incident Management with enforced lifecycle states and SLA breach detection",
      "Real-time updates using WebSockets for live incident activity",
      "Workflow and task management scoped to teams",
      "Knowledge base with markdown support, versioning and search",
      "Team-based multi-tenancy with strict data isolation",
      "Role-based access control (Admin, Manager, Engineer and Viewer)",
      "Audit trails and timelines for all incident activity",
      "Postmortem documentation linked to resolved incidents"
    ],
    "challenges": [
      "Dual-database strategy separating transactional data from event logs",
      "Multi-tenant security model with team-level data isolation",
      "Real-time incident updates without background workers",
      "SLA calculations with breach detection and health metrics",
      "Production-grade error handling, validation, and logging",
      "Free-tier optimized infrastructure without sacrificing reliability"
    ],
    "outcomes": [
      "Production-ready system with 50+ API endpoints",
      "Real-time incident updates without paid infrastructure",
      "Secure, team-based multi-tenant architecture",
      "Fully documented setup and deployment guides",
      "Responsive UI across mobile, tablet, and desktop"
    ],
    "metrics": [
      {
        "label": "API Endpoints",
        "value": "50+",
        "description": "RESTful API with comprehensive features"
      },
      {
        "label": "Databases",
        "value": "2",
        "description": "PostgreSQL + MongoDB architecture"
      },
      {
        "label": "Real-time Updates",
        "value": "WebSockets",
        "description": "Live incident activity without polling"
      },
      {
        "label": "Access Control",
        "value": "RBAC + Teams",
        "description": "Role and team-based permissions"
      }
    ],
    "links": {
      "live": "",
      "github": "https://github.com/Ancel-duke/OpsFlow"
    },
    "images": {
      "hero": "/assets/projects/opsflow.jpg",
      "before": "/assets/projects/opsflow.jpg",
      "after": "/assets/projects/opsflow.jpg",
      "gallery": [
        "/assets/projects/opsflow.jpg"
      ]
    }
  },
  {
    "id": 14,
    "slug": "signflow",
    "title": "SignFlow - Real-Time Assistive Tech Simulation for Sign Language",
    "subtitle": "Building a high-fidelity assistive technology simulation for real-time sign language translation",
    "role": "Full-Stack Software Engineer",
    "timeline": "4 months",
    "year": "2026",
    "status": "Completed",
    "description": "SignFlow is a high-fidelity assistive technology platform architected for real-time sign language translation, exploring the architectural requirements for scaling accessibility platforms. The system features WebSocket-powered streaming, 3D avatar simulation with natural variation, and accessibility-first design with WCAG compliance, demonstrating production-grade architecture for specialized user bases.",
    "problem": "Current text-to-sign demonstrations suffer from robotic user experience with repetition, static nature, latency issues, and UX gaps. Identical animations play for every word without variation, there's a lack of timing, facial expression, or prosody, poor real-time feedback loops, and negligible consideration for accessibility. For assistive technology to be trusted by the Deaf and Hard-of-Hearing community, naturalness and responsiveness are as critical as linguistic correctness.",
    "problemSolutionBridge": "To move from robotic loops to a responsive, natural-feeling interpreter, I built SignFlow so translation streams in real time and the 3D avatar varies per phrase, with failures in rendering or network isolated from the core experience.",
    "solution": "I architected SignFlow as a sophisticated assistive technology platform with dynamic logic for per-word and phrase-based animation sequences, live streaming via WebSocket-powered translation for near-zero latency, responsive interface with high-fidelity 3D avatar that reacts to user input, and accessibility-first design with UI built specifically for inclusive user experiences. By applying subtle variations to repeated inputs, SignFlow creates the illusion of a living interpreter rather than a looped animation, demonstrating production-grade architecture for specialized user bases.",
    "keyTerms": [
      { "term": "Animation pools (seed-based variation)", "explanation": "SignFlow stores multiple animation variants per word or phrase and picks one by seed so repeated words do not look identical; that supports the project goal of natural, human-like signing instead of a single loop." },
      { "term": "WebSocket streaming", "explanation": "Text is sent over a WebSocket and sign sequences stream back so latency stays low; for this assistive product that keeps the experience responsive and real-time without polling." },
      { "term": "3D rendering isolation", "explanation": "Three.js/React Three Fiber runs in a layer separate from translation and API so a render glitch or heavy frame does not block the translation pipeline or crash the app." }
    ],
    "failureModes": "WebSocket disconnect: client reconnects and can resend input so the user is not stuck. 3D render or GPU failure: error boundaries contain the avatar component so the rest of the UI (text, controls) still works and we can show a fallback or retry. Translation service or DB slow: we show loading and timeouts so the user knows the system is working; we do not block the main thread. Missing animation for a word: we fall back to spelling or a default so the experience degrades gracefully instead of breaking.",
    "impact": "Fully implemented assistive technology prototype demonstrating real-time system design using WebSockets, scalable cloud architecture with MongoDB Atlas, intentional UX for specialized user bases, and product-level thinking bridging coding projects and viable market solutions. The platform features high-fidelity 3D avatar simulation, natural variation in animations, comprehensive analytics dashboard, and full WCAG accessibility compliance, showcasing enterprise-grade architecture for accessibility platforms.",
    "architecture": "SignFlow follows a real-time streaming architecture: React frontend with Three.js (React Three Fiber) for 3D avatar rendering, Node.js/Express backend for translation processing, MongoDB Atlas for cloud-hosted data with indexed collections, and WebSocket connections for near-zero latency streaming. Animation pools store multiple variations per word/phrase, with seed-based selection for natural variation. The architecture separates 3D rendering from translation logic, ensuring smooth performance. Analytics are computed on-demand using MongoDB aggregation pipelines.",
    "isolation": "Service isolation is achieved through separate layers: 3D rendering is isolated from translation processing, preventing rendering failures from affecting translation. WebSocket connections are handled independently from REST API routes. Animation pools are cached client-side, reducing server load. Error handling is centralized with custom exception handlers, preventing cascading failures. Database operations use MongoDB transactions for atomic updates. Frontend error boundaries isolate 3D rendering failures, maintaining application stability. Accessibility features are isolated in dedicated components, ensuring WCAG compliance.",
    "tradeoffs": "I chose WebSocket streaming over REST polling because near-zero latency was essential for sign-to-text feel, trading some complexity for real-time responsiveness. I selected Three.js over 2D animations because the immersive 3D avatar better served accessibility and user trust. I implemented animation pools over single animations so signing had natural variation and felt less robotic. I used MongoDB Atlas over self-hosted for cloud scalability and ops simplicity. I deferred voice input and video recording to ship the core translation experience first.",
    "implementationStatus": "Completed (~70%): Core real-time translation engine, 3D avatar simulation, natural animation variation, WebSocket streaming, analytics dashboard, accessibility compliance (WCAG), and responsive UI. Deferred: Voice input support, video recording, multiple avatar options, sign language learning modules, community features, and mobile native apps.",
    "potentialExpansion": "Vision includes scaling to 10,000+ concurrent users through WebSocket load balancing, Redis for session management, and CDN integration for 3D assets. Planned containerization with Docker for consistent deployments. Advanced features include AI-powered sign recognition, multiple avatar personalization, sign language learning modules, and community sharing capabilities. Enterprise features include API access for third-party integrations, white-label customization, and comprehensive analytics dashboards.",
    "technologies": [
      {
        "name": "React",
        "category": "Frontend",
        "icon": "react"
      },
      {
        "name": "Node.js",
        "category": "Backend",
        "icon": "nodejs"
      },
      {
        "name": "Express",
        "category": "Backend",
        "icon": "express"
      },
      {
        "name": "MongoDB",
        "category": "Database",
        "icon": "mongodb"
      },
      {
        "name": "WebSockets",
        "category": "Real-time",
        "icon": "socketio"
      },
      {
        "name": "Three.js",
        "category": "3D Graphics",
        "icon": "threejs"
      },
      {
        "name": "React Three Fiber",
        "category": "3D Graphics",
        "icon": "react"
      },
      {
        "name": "JWT",
        "category": "Authentication",
        "icon": "jwt"
      },
      {
        "name": "Recharts",
        "category": "Visualization",
        "icon": "recharts"
      },
      {
        "name": "Framer Motion",
        "category": "Animation",
        "icon": "framer"
      }
    ],
    "features": [
      "Real-time translation engine with streaming input via WebSockets",
      "Believable avatar simulation with phrase mapping and animation pooling",
      "Natural variation with variable animation speeds and micro-expressions",
      "Immersive and accessible UI with split-screen design",
      "Analytics and insights dashboard with session metrics",
      "Full accessibility support with ARIA compliance and keyboard navigation",
      "High-contrast modes and adjustable font sizes",
      "Interactive timeline with hover previews and AI-powered suggestions"
    ],
    "challenges": [
      "Implementing real-time WebSocket streaming for near-zero latency translation",
      "Creating natural variation in animations to prevent robotic movement",
      "Building high-fidelity 3D avatar with micro-expressions and natural body movements",
      "Designing accessible UI for specialized user bases with full ARIA compliance",
      "Optimizing animation performance for smooth real-time rendering",
      "Implementing phrase detection and special animation sequences"
    ],
    "outcomes": [
      "Fully functional assistive technology prototype with production-grade architecture",
      "Real-time translation system with WebSocket-powered streaming",
      "High-fidelity 3D avatar with natural variation and micro-expressions",
      "Comprehensive analytics dashboard with interactive charts and user insights",
      "Full accessibility compliance with WCAG standards",
      "Scalable cloud architecture with MongoDB Atlas"
    ],
    "metrics": [
      {
        "label": "Real-time Latency",
        "value": "Near-zero",
        "description": "WebSocket-powered streaming"
      },
      {
        "label": "Animation Variations",
        "value": "Multiple",
        "description": "Per-word animation pools with natural variation"
      },
      {
        "label": "Accessibility",
        "value": "WCAG Compliant",
        "description": "Full ARIA support and keyboard navigation"
      },
      {
        "label": "Database",
        "value": "MongoDB Atlas",
        "description": "Cloud-hosted with indexed collections"
      }
    ],
    "links": {
      "live": "",
      "github": "https://github.com/Ancel-duke/SignFlow"
    },
    "images": {
      "hero": "/assets/projects/signflow1.jpg",
      "before": "/assets/projects/signflow1.jpg",
      "after": "/assets/projects/signflow2.jpg",
      "gallery": [
        "/assets/projects/signflow1.jpg",
        "/assets/projects/signflow2.jpg",
        "/assets/projects/flow.jpg",
        "/assets/projects/flow2.jpg"
      ]
    }
  },
  {
    "id": 15,
    "slug": "nestfi",
    "title": "NestFi â€” Resilient Financial Coordination Platform",
    "subtitle": "Correctness-first finance with hybrid storage, M-Pesa B2C, and failure-aware design",
    "role": "Full-Stack Software Engineer",
    "timeline": "Ongoing",
    "year": "2026",
    "status": "In Progress",
    "description": "NestFi is a production-grade finance platform designed for financial correctness under failure. Built by Ancel Ajanga, it ensures predictable behavior across asynchronous payment providers, delayed or duplicated callbacks, unreliable networks, and hybrid storage layers. PostgreSQL enforces ledger integrity, MongoDB handles compliance and audit events, and Redis provides ephemeral caching and distributed locking with fail-closed safety. Real-time notifications via Socket.io and hardened M-Pesa Daraja integrations make the system resilient, auditable, and user-trust oriented.",
    "problem": "Building a finance system isnâ€™t CRUD â€” itâ€™s correctness under failure. NestFi must remain predictable when payment providers are asynchronous, callbacks are delayed or duplicated, caches fail, logs are temporarily unavailable, and network conditions are unreliable. The core challenge is fault isolation and ledger correctness across multiple storage models and external integrations.",
    "problemSolutionBridge": "To keep the ledger correct when callbacks are late or duplicated and caches or logs fail, I designed NestFi so PostgreSQL is the single source of truth, every external integration is idempotent and failure-contained, and withdrawals follow a request â†’ approval â†’ execution â†’ callback lifecycle with database-enforced idempotency.",
    "solution": "Hybrid storage: PostgreSQL (wallets, ledgers), MongoDB (events, audit & compliance logs), Redis (locks, queues, rate limits). Service isolation: stateless NestJS backend (JWT), restart-safe, horizontally scalable. Failure-aware external integration: M-Pesa Daraja flows are idempotent, timeout-aware, and guarded by retries, backoff, and circuit breakers. Real-time UX: mobile deposits and withdrawals update instantly via Socket.io when callbacks are processed. Audit & compliance: structured, immutable event logging for KYC, withdrawals, disputes, and fee/tax handling. System guarantees include financial correctness (ledger-backed double-entry; totals net to zero), withdrawal safety (B2C lifecycle with DISPUTED state for manual reconciliation), resilience (fail-closed distributed locks with renewal), real-time trust loop (explicit states e.g. Settling), compliance & audit (MongoDB), rate limiting (Redis primary, Postgres fallback), and data safety (Postgres = truth, MongoDB = audit, Redis = ephemeral).",
    "keyTerms": [
      { "term": "Idempotent callback processing", "explanation": "In NestFi, M-Pesa callbacks are processed so duplicate or delayed deliveries do not double-credit or double-debit; that supports the goal of ledger correctness when the provider is asynchronous and unreliable." },
      { "term": "Double-entry accounting", "explanation": "All wallet updates are ledger-backed; every transaction debits and credits system accounts such that totals always net to zero." },
      { "term": "Fail-closed distributed locks", "explanation": "Autosave batching and other critical jobs use distributed locks with renewal; execution aborts if lock ownership cannot be proven, so the system never proceeds under ambiguity." }
    ],
    "failureModes": "M-Pesa callback duplicate or delayed: idempotent handling and correlation IDs ensure we apply the effect once. Redis down: we bypass cache and rate limits (Postgres fallback) so auth and core API still work. MongoDB down: we skip event logging so writes to PostgreSQL are not blocked. Backend crash: stateless design and JWT allow restart without session loss; ledger state is only in PostgreSQL. Network timeout to provider: circuit breakers and retries with backoff prevent cascading failure. Withdrawal ambiguity: B2C ResultCode success does not imply user receipt; withdrawals can enter DISPUTED state for manual reconciliation.",
    "impact": "NestFi demonstrates capstone-level engineering: correctness-first design where financial truth is never inferred; explicit handling of distributed-system failure modes (timeouts, split-brain risk, replayed callbacks); real-time, user-trust-focused payment experience; strong auditability and compliance foundations aligned with Kenyan fintech regulations; architecture optimized for resilience, not feature count. Completion ~87% â€” core architecture, ledger, M-Pesa B2C, mobile deposits, autosave batching, and audit flows fully implemented.",
    "isolation": "Core responsibilities run independently: the backend orchestrates logic and is safe to restart; PostgreSQL remains the financial source of truth with no silent corruption; MongoDB (events/audit) is optional during failure; Redis is a performance and locking layer that can be bypassed or fall back to Postgres; M-Pesa callbacks are processed in an idempotent, delay-tolerant manner. Security and network isolation are enforced via Docker and minimal exposed ports, with TLS at the edge via Cloudflare.",
    "tradeoffs": "I chose hybrid storage (PostgreSQL, MongoDB, Redis) because it matches real financial constraints: PostgreSQL for ledger correctness, MongoDB for events and audit, Redis for low-latency ephemeral state and distributed locking. I accepted higher operational complexity in exchange for clear failure boundaries and auditability. I prioritized correctness, resilience, and auditability over feature count. Current gaps are intentional: Web KYC file upload is placeholder (manual verification); some flows use direct service calls instead of full event bus; integration, load, and contract tests pending; optional UX and operational tooling.",
    "implementationStatus": "Completion ~87%. Core architecture, ledger, M-Pesa B2C, mobile deposits, autosave batching, and audit flows fully implemented. Remaining work is operational hardening and UX refinement, not foundational correctness. Documentation is maintained alongside the codebase; Dockerized workflow supports deterministic builds.",
    "potentialExpansion": "Web KYC automation (OCR/verification). Full event bus adoption (publish/subscribe) for remaining flows. Integration, load, and contract tests. Frontend and operational tooling polish. Deeper observability, trace correlation across callbacks, runbooks, and replay tooling for event/callback recovery.",
    "technologies": [
      { "name": "NestJS", "category": "Backend", "icon": "nestjs" },
      { "name": "TypeScript", "category": "Language", "icon": "typescript" },
      { "name": "PostgreSQL", "category": "Database", "icon": "postgresql" },
      { "name": "MongoDB", "category": "Database", "icon": "mongodb" },
      { "name": "Redis", "category": "Cache", "icon": "redis" },
      { "name": "Docker", "category": "DevOps", "icon": "docker" },
      { "name": "Cloudflare Workers", "category": "Edge", "icon": "cloudflare" },
      { "name": "M-Pesa Daraja", "category": "Integration", "icon": "api" },
      { "name": "JWT", "category": "Authentication", "icon": "jwt" },
      { "name": "Socket.io", "category": "Real-time", "icon": "socketio" },
      { "name": "React Native", "category": "Mobile", "icon": "react" },
      { "name": "Next.js", "category": "Frontend", "icon": "nextjs" },
      { "name": "RabbitMQ", "category": "Messaging", "icon": "api" }
    ],
    "features": [
      "Ledger-backed wallets with strict double-entry accounting (KES-only)",
      "M-Pesa B2C withdrawals with idempotent handling and dispute-aware lifecycle",
      "Mobile deposits via POST /payments/deposit with real-time Socket.io updates",
      "Autosave batching with fail-closed + lock renewal safety",
      "Compliance and audit logging (MongoDB)",
      "Identity-aware rate limiting (Redis + Postgres fallback)",
      "Push notifications via registered tokens and background worker",
      "Stateless NestJS backend (horizontally scalable, restart-safe)",
      "Resilience patterns: timeouts, retries with backoff, circuit breakers, graceful degradation",
      "Security-first baseline: JWT auth, validation, rate limiting, callback IP allowlisting, TLS at the edge"
    ],
    "challenges": [
      "Designing idempotent, delay-tolerant callback processing for M-Pesa B2C and STK",
      "Preventing cascading failures across cache/log/payment dependencies",
      "Choosing data stores by guarantees (ACID ledgers vs event logs vs ephemeral state)",
      "Enforcing withdrawal safety and DISPUTED state when provider response is ambiguous",
      "Fail-closed distributed locking with renewal for autosave and critical jobs",
      "Hardening service isolation with Docker networks and minimal exposed ports"
    ],
    "outcomes": [
      "Correctness-first architecture; financial truth is never inferred",
      "Explicit handling of distributed-system failure modes (timeouts, replayed callbacks)",
      "Real-time payment experience with Socket.io and explicit state transitions",
      "Strong auditability and compliance aligned with Kenyan fintech regulations",
      "Hybrid database model and clear isolation boundaries; completion ~87%"
    ],
    "metrics": [
      { "label": "Completion", "value": "~87%", "description": "Core architecture, ledger, M-Pesa B2C, mobile deposits, autosave, audit flows implemented" },
      { "label": "Datastores", "value": "3", "description": "PostgreSQL + MongoDB + Redis hybrid model" },
      { "label": "Payment Integration", "value": "M-Pesa Daraja", "description": "STK Push & B2C callbacks, idempotent processing" },
      { "label": "Resilience", "value": "Circuit breakers + fail-closed locks", "description": "Timeouts, retries, backoff, lock renewal" }
    ],
    "links": {
      "live": "",
      "github": "https://github.com/Ancel-duke/NestFi",
      "docs": "https://github.com/Ancel-duke/NestFi/blob/main/docs/ARCHITECTURE.md"
    },
    "images": {
      "hero": "/assets/projects/nestfi.jpg",
      "before": "/assets/projects/nestfi.jpg",
      "after": "/assets/projects/nestfi.jpg",
      "gallery": [
        "/assets/projects/nestfi.jpg"
      ]
    }
  },
  {
    "id": 16,
    "slug": "edumanage",
    "title": "EduManage â€” Multi-Tenant School Management SaaS",
    "subtitle": "Streamlining administration, enrollment, and reporting for schools",
    "role": "Full-Stack Software Engineer",
    "timeline": "5 months",
    "year": "2025",
    "status": "Completed",
    "description": "A comprehensive educational management system designed to streamline administrative tasks, student enrollment, and academic reporting.",
    "problem": "Schools often rely on fragmented tooling (spreadsheets, paper records, disconnected apps) for enrollment, administration, and reporting. This creates duplicate data entry, inconsistent records, and slow reporting cyclesâ€”especially when multiple staff roles require different access levels.",
    "problemSolutionBridge": "To replace fragmented tools with one system without mixing school data or permissions, I built EduManage with tenant-scoped access and hierarchical RBAC so failures in one institution or module do not affect others.",
    "solution": "I built EduManage to centralize core school operations into a single system with clear role boundaries. The platform focuses on predictable workflows for student enrollment, administrative management, and academic reporting, with structured access control and a backend designed to handle growth and operational complexity.",
    "keyTerms": [
      { "term": "Tenant-scoped data access", "explanation": "Every EduManage request is filtered by institution so one school never sees another's data; that supports the project goal of multi-tenant SaaS on a single deployment with strict isolation." },
      { "term": "Hierarchical RBAC", "explanation": "Roles and permissions form a hierarchy so complex school structures (admin, teacher, secretary) map to predictable access without per-user exceptions; that supports scalable, auditable authorization." },
      { "term": "Real-time events (Socket.io)", "explanation": "Notifications and updates are delivered over scoped channels so only the right tenant receives them; that supports live workflows without cross-tenant leakage or polling." }
    ],
    "failureModes": "MongoDB or backend down: the app returns clear errors so clients can show retry or offline messaging. Socket.io disconnect: clients reconnect and re-subscribe so they do not miss tenant-scoped updates. Invalid or expired JWT: auth middleware rejects the request and the frontend can redirect to login. Cross-tenant request (bug or abuse): every query is tenant-scoped so data from another institution is never returned. Heavy report or export: we avoid blocking other requests so one school's job does not slow the whole system.",
    "impact": "Delivered a unified school operations platform that reduces administrative overhead, improves record consistency, and enables faster, more reliable reporting. The system is structured for maintainability, with clear module boundaries that support incremental expansion over time.",
    "isolation": "Tenant isolation is enforced at the data access layer so every request is scoped to an institution. Auth and authorization are stateless (JWT) and hierarchical (RBAC), and real-time event delivery is isolated through Socket.io channels to prevent cross-tenant leakage. The system is built to degrade gracefully when non-critical subsystems are impaired.",
    "tradeoffs": "I chose to ship EduManage at ~85% to reflect real-world constraints: I deferred advanced rate limiting, deeper automated testing, and caching in favor of delivering a stable, well-structured MVP with strong tenant and authorization boundaries first.",
    "implementationStatus": "Status: MVP Complete (~85%). Core multi-tenancy, RBAC, and real-time events are implemented. Deferred: advanced rate limiting, deeper automated test coverage, and advanced caching layers.",
    "potentialExpansion": "Add advanced caching for hot reads, rate limiting and abuse protection, deeper automated testing (unit + integration), audit trails for sensitive operations, and expanded real-time notification pipelines.",
    "technologies": [
      { "name": "NestJS", "category": "Backend", "icon": "nestjs" },
      { "name": "Express.js", "category": "Backend", "icon": "express" },
      { "name": "MongoDB", "category": "Database", "icon": "mongodb" },
      { "name": "JWT", "category": "Authentication", "icon": "jwt" },
      { "name": "RBAC", "category": "Security", "icon": "security" },
      { "name": "Socket.io", "category": "Real-time", "icon": "socketio" },
      { "name": "TypeScript", "category": "Language", "icon": "typescript" },
      { "name": "Docker", "category": "DevOps", "icon": "docker" }
    ],
    "features": [
      "Multi-tenant backend with tenant-scoped data access",
      "JWT-based stateless authentication",
      "Hierarchical RBAC for complex school permissions",
      "Real-time notifications and updates via Socket.io",
      "Failure-aware design with graceful degradation",
      "Dockerized development and deployment workflow"
    ],
    "challenges": [
      "Enforcing tenant isolation across all access paths",
      "Keeping authorization logic predictable as roles and permissions expand",
      "Designing real-time events without cross-tenant leakage",
      "Modeling flexible academic domain entities in MongoDB",
      "Building for partial failures without degrading core workflows"
    ],
    "outcomes": [
      "MVP complete with production-ready tenant and authorization boundaries",
      "Real-time operational workflows supported via event-driven updates",
      "Architecture documented and maintained in GitHub docs"
    ],
    "metrics": [
      { "label": "Status", "value": "~85%", "description": "MVP complete; hardening and optimizations deferred" },
      { "label": "Multi-Tenancy", "value": "Tenant-scoped", "description": "Institution isolation enforced at data layer" },
      { "label": "AuthZ", "value": "Hierarchical RBAC", "description": "Role and permission boundaries designed to scale" },
      { "label": "Real-time", "value": "Socket.io", "description": "Notifications and operational updates" }
    ],
    "links": {
      "live": "",
      "github": "https://github.com/Ancel-duke/edumanage",
      "docs": "https://github.com/Ancel-duke/edumanage/blob/main/docs/ARCHITECTURE.md"
    },
    "images": {
      "hero": "/assets/projects/edumanage.jpg",
      "before": "/assets/projects/edumanage.jpg",
      "after": "/assets/projects/edumanage.jpg",
      "gallery": [
        "/assets/projects/edumanage.jpg"
      ]
    }
  },
  {
    "id": 17,
    "slug": "aegis",
    "title": "Aegis â€” Self-Healing Infrastructure with Policy and AI",
    "subtitle": "Intelligent monitoring, policy-driven decisions, and safe Kubernetes automation",
    "role": "Full-Stack Software Engineer",
    "timeline": "Ongoing",
    "year": "2026",
    "status": "Live",
    "description": "Aegis monitors infrastructure behavior, detects anomalies using AI, evaluates security policies, and executes tightly controlled remediation actions. It is built with strict isolation boundaries, auditability, and failure-aware automation to avoid unsafe self-healing.",
    "problem": "Modern infrastructure fails silently. Teams only react after damage is done, and automation often introduces more risk than it removes. Monitoring tools detect issues but don't act; automation tools act but aren't safe; security and operations are disconnected; AI systems make decisions without accountability.",
    "problemSolutionBridge": "To make automation safe and auditable, I separated observation, intelligence, policy, and execution so the AI recommends but never executesâ€”and every action is policy-checked and signed.",
    "solution": "I built Aegis around four controlled layers: Observation (metrics, logs, traces, events), Intelligence (AI-driven anomaly detection), Policy (explicit, auditable rules for what is allowed), and Execution (isolated, signed, least-privilege actions). Automation is only allowed when policy, identity, and safety constraints all pass.",
    "keyTerms": [
      { "term": "AI-driven anomaly detection", "explanation": "In Aegis the AI engine analyzes metrics and logs to flag anomalies and recommend actions; it never executes directly, so the project goal of safe, auditable automation is preservedâ€”humans and policy stay in control." },
      { "term": "Failure-aware automation", "explanation": "Remediation (e.g. pod restart, rollback) runs only after policy evaluation and HMAC-signed intent; if the executor or policy service is down, no action is taken so we avoid unsafe or blind self-healing." },
      { "term": "Policy-as-code (explicit allowlisting)", "explanation": "What the executor can do is defined in policy (namespaces, actions); the AI cannot override it, so every automated action is traceable and bounded to what the operator allowed." }
    ],
    "failureModes": "AI engine down: we stop recommending new actions but existing policy and executor still work; no blind execution. Executor down: no remediation runs until it recovers; observation and policy are unchanged. Policy service down: executor refuses to run actions so we fail closed. Kubernetes API unreachable: executor returns clear errors and does not retry indefinitely. Audit log failure: we do not execute the action so we never have unaudited changes. HMAC or signature invalid: executor rejects the request so only authorized callers can trigger actions.",
    "impact": "Aegis guarantees: no unaudited actions, no blind AI execution, no privilege escalation, no silent failures. Security highlights include JWT + RBAC, HMAC-signed executor actions, namespace allowlisting, immutable audit logs, and default-deny network policies. The platform is designed so an ethical hacker can reason about what cannot happen.",
    "architecture": "Core services: Backend (NestJS) â€” Auth, policies, audit, APIs; AI Engine (FastAPI) â€” Anomaly detection and recommendations; Executor Service â€” Secure Kubernetes actions; Frontend (Next.js) â€” Observability and control plane UI. Infrastructure: Docker and Kubernetes, PostgreSQL and Redis, Prometheus, Grafana, Loki, Tempo, CI/CD with security scanning, Cloudflare (WAF, webhook protection). Every service is isolated, auditable, and deployable independently.",
    "isolation": "The AI detects anomalies, assigns severity, and recommends actionsâ€”but cannot execute actions directly, override policies, or bypass audit logging. AI informs decisions; policy authorizes actions; humans retain control. Self-healing means restarting unhealthy pods, scaling deployments safely, rolling back bad releases, and temporarily isolating services. Explicitly not supported: arbitrary command execution, destructive actions, unbounded automation loops.",
    "tradeoffs": "Implemented (~95%): Backend APIs and security, AI anomaly detection, executor with Kubernetes RBAC, full observability stack, production-ready frontend, Docker and Kubernetes manifests, CI/CD with rollback. Not yet implemented: mTLS between services, WebSocket backend, full E2E test suite, AI model persistence, external security audit. Known gaps are documented, intentional, and scoped.",
    "implementationStatus": "Implemented (~95%): Backend APIs and security, AI anomaly detection, executor with Kubernetes RBAC, full observability stack, production-ready frontend, Docker and Kubernetes manifests, CI/CD with rollback. Not yet: mTLS, WebSocket backend, full E2E test suite, AI model persistence, external security audit.",
    "potentialExpansion": "Architecture avoids unsafe automation, prioritizes auditability, separates decision from execution, and scales from single cluster to multi-cluster. Matches real production failure modes. Aegis reflects how I think about production systems: assume failure, design for abuse, automate carefully, and leave a trail of evidence for every decision.",
    "technologies": [
      { "name": "NestJS", "category": "Backend", "icon": "nestjs" },
      { "name": "FastAPI", "category": "Backend", "icon": "python" },
      { "name": "Next.js", "category": "Frontend", "icon": "nextjs" },
      { "name": "PostgreSQL", "category": "Database", "icon": "postgresql" },
      { "name": "Redis", "category": "Cache", "icon": "redis" },
      { "name": "Kubernetes", "category": "DevOps", "icon": "kubernetes" },
      { "name": "Docker", "category": "DevOps", "icon": "docker" },
      { "name": "Prometheus", "category": "Observability", "icon": "prometheus" },
      { "name": "Grafana", "category": "Observability", "icon": "grafana" },
      { "name": "JWT", "category": "Authentication", "icon": "jwt" },
      { "name": "TypeScript", "category": "Language", "icon": "typescript" },
      { "name": "Python", "category": "Language", "icon": "python" }
    ],
    "features": [
      "Policy-driven access control and self-healing decisions",
      "ML-based anomaly and failure detection (AI engine)",
      "Safe Kubernetes operations (restart, scale, rollback)",
      "HMAC-signed executor actions and namespace allowlisting",
      "Immutable audit logs and default-deny network policies",
      "Full observability stack (Prometheus, Grafana, Loki, Tempo)",
      "Production-ready Next.js dashboard and control plane UI"
    ],
    "challenges": [
      "Keeping AI recommendations strictly advisoryâ€”no direct execution",
      "Enforcing policy evaluation and audit for every action",
      "Isolating executor with minimal Kubernetes RBAC",
      "Designing for failure and partial outages without unsafe automation"
    ],
    "outcomes": [
      "No unaudited actions; no blind AI execution; no privilege escalation",
      "Self-healing within policy: pod restart, scale, rollback only when allowed",
      "Documented architecture and honest status (implemented vs not yet)",
      "Production mindset: assume failure, design for abuse, automate carefully"
    ],
    "metrics": [
      { "label": "Status", "value": "~95%", "description": "Backend, AI engine, executor, frontend, observability complete" },
      { "label": "Security", "value": "Policy + HMAC", "description": "Every action policy-evaluated and signed" },
      { "label": "AI Role", "value": "Recommend only", "description": "AI informs; policy authorizes; humans control" },
      { "label": "Audit", "value": "Immutable", "description": "Trail of evidence for every decision" }
    ],
    "links": {
      "live": "",
      "github": "https://github.com/Ancel-duke/Aegis",
      "docs": "https://github.com/Ancel-duke/Aegis/blob/main/ARCHITECTURE.md"
    },
    "images": {
      "hero": "/assets/projects/aegis.jpg",
      "before": "/assets/projects/aegis.jpg",
      "after": "/assets/projects/aegis.jpg",
      "gallery": [
        "/assets/projects/aegis.jpg"
      ]
    }
  },
  {
    "id": 18,
    "slug": "fits-by-aliv",
    "title": "Fits by Aliv â€” Kenya-First E-Commerce with Payment-Safe Workflows",
    "subtitle": "Production-grade e-commerce with inventory self-healing, M-Pesa verification, and hardened security",
    "role": "Full-Stack Software Engineer",
    "timeline": "Ongoing",
    "year": "2026",
    "status": "Live",
    "description": "Fits by Aliv is a Kenya-first e-commerce marketplace (thrift/sustainable fashion) with payment-safe workflows, inventory self-healing, and hardened security. Backend is NestJS with PostgreSQL (Prisma); clients are Flutter (mobile, web, desktop). Identity is Firebase Auth; payments are M-Pesa via Safaricom Daraja API.",
    "problem": "E-commerce systems in emerging markets fail differently. Payments are asynchronous, networks are unreliable, and inventory errors directly translate to lost revenue and customer trust. Most platforms assume synchronous payments, over-trust callbacks, allow double-spend scenarios, or leak business logic across client and backend boundaries. Inventory overselling, voucher abuse, replay attacks, and unsafe automation are common failure modes. Kenya-specific constraints compound the problem: M-Pesa STK Push is asynchronous and non-authoritative, VAT/WHT rules are strict, and mobile devices are often resource-constrained.",
    "problemSolutionBridge": "To avoid oversell and double-spend when payments are async and callbacks unreliable, I designed Fits by Aliv so we never trust a callback until we verify with STK Query, and inventory is only reserved softly until payment is confirmed.",
    "solution": "I built Fits by Aliv as a production-grade e-commerce backend around failure, abuse, and latency as first-class concerns. The system uses soft inventory reservations, idempotent order creation, verified payment reconciliation (Daraja STK Query before state changes), and AI-assisted self-healing background jobs. Payments are never trusted at face value; inventory is never hard-deducted before confirmation; automation is bounded, auditable, and reversible. All business logic lives in a single NestJS backend with PostgreSQL transactions. Clients never touch the database. Firebase is used strictly for identity; authorization, rate-limiting, replay prevention, and auditability are enforced server-side.",
    "keyTerms": [
      { "term": "Idempotent order creation", "explanation": "In Fits by Aliv every order mutation accepts an idempotency key so duplicate requests (e.g. double-tap or retry) create only one order; that supports the goal of no double-charge and no duplicate reservations." },
      { "term": "Verified payment reconciliation", "explanation": "We never update order or payment state from a callback alone; we call Daraja STK Query to confirm status first, so the project goal of no blind trust in M-Pesa callbacks is met." },
      { "term": "Soft inventory reservations", "explanation": "Stock is reserved for a TTL instead of hard-deducted at checkout; if payment does not complete, the reservation expires and inventory is released, preventing oversell and supporting async payment flows." }
    ],
    "failureModes": "M-Pesa callback before verification: we do not update state until STK Query confirms; duplicate callbacks are idempotent. Reservation expiry: BullMQ jobs release expired reservations so stock is not stuck. Voucher double-spend: conditional UPDATE inside the order transaction ensures one voucher use per redemption. Database or backend crash: Prisma transactions keep order, voucher, and inventory consistent; we do not commit partial state. Replay or abuse: idempotency keys, nonce, and rate limiting limit impact. Self-healing job failure: jobs are bounded and dead-lettered so we do not retry forever or mutate data blindly.",
    "impact": "The system guarantees: no inventory oversell due to race conditions, no voucher double-spend, no unaudited state changes, no blind trust in payment callbacks, no unbounded automation. Security highlights: Firebase JWT verification + server-side authorization, idempotency keys on all critical mutations, replay-prevention via nonce + timestamp, IP allowlisting and optional HMAC for webhooks, immutable audit and security event logs. The system is designed so an ethical hacker can reason about what cannot happen.",
    "architecture": "Request layer: Flutter clients authenticate via Firebase JWT; every mutation supports idempotency. Transactional core: Orders, vouchers, inventory reservations, and tax records are created atomically in a single Prisma transaction. Asynchronous layer: BullMQ + Redis handle reservation expiry, payment verification, retries, and dead-letters. Verification layer: M-Pesa callbacks are validated, allowlisted, and verified via STK Query before state changes. Healing layer: Background jobs classify failures and execute bounded recovery actions. Audit layer: Every sensitive action leaves a durable trail. Modules: Auth, Users, Orders, Payments, Products, Categories, Cart, Wishlist, Vouchers, Referrals, Notifications, Admin, Audit, Healing, Tax, Upload, Security, Common, Prisma, Firebase, Mpesa.",
    "isolation": "Self-healing exists, but automation is constrained. Inventory reservations expire automatically if payment does not complete. Payment verification retries are bounded and adaptive. Dead-letter jobs are quarantined and never auto-replayed blindly. AI can classify and recommend actions but cannot execute arbitrary commands, bypass policies, override transactional rules, or mutate data without audit logs. Explicitly not supported: client-side inventory mutation, trusting payment callbacks without verification, hard inventory deduction before payment, unbounded retries or automation loops.",
    "tradeoffs": "I removed Supabase in favor of a single NestJS backend and Prisma because I wanted vendor decoupling and full control over migrations. I retained Firebase Auth for JWT issuance and SDK support; the backend only verifies tokens. I chose Prisma over raw SQL for type safety and migrations, and use raw SQL only for the conditional voucher UPDATE. I use Redis for BullMQ (reservation-expiry, payment-verification, dead-letter) and for replay-prevention when configured.",
    "implementationStatus": "~90â€“95% Complete: Backend APIs & database schema, inventory reservation & expiry, payment verification & reconciliation, AI-assisted self-healing jobs, admin analytics & exports, security hardening & audit trails. Remaining work is operational, not architectural. Not yet (intentional): multi-region deployment, external penetration test, automated tax filing integrations, full E2E mobile test suite.",
    "potentialExpansion": "Additional payment providers (schema-compatible), multi-seller inventory, regional tax rules, event-driven analytics, fraud scoring models feeding the healing layer. The core system already assumes failure, retries, abuse, and human oversight.",
    "technologies": [
      { "name": "NestJS", "category": "Backend", "icon": "nestjs" },
      { "name": "TypeScript", "category": "Language", "icon": "typescript" },
      { "name": "PostgreSQL", "category": "Database", "icon": "postgresql" },
      { "name": "Prisma", "category": "ORM", "icon": "prisma" },
      { "name": "Redis", "category": "Cache", "icon": "redis" },
      { "name": "BullMQ", "category": "Queue", "icon": "redis" },
      { "name": "Flutter", "category": "Mobile", "icon": "flutter" },
      { "name": "Firebase Auth", "category": "Authentication", "icon": "firebase" },
      { "name": "M-Pesa Daraja", "category": "Integration", "icon": "api" }
    ],
    "features": [
      "Soft inventory reservations with TTL; no hard deduction before payment",
      "Idempotent order creation with X-Idempotency-Key",
      "M-Pesa STK Push + STK Query verification before state changes",
      "BullMQ jobs: reservation-expiry, payment-verification, dead-letter",
      "Voucher redemption inside order transaction (pessimistic conditional UPDATE)",
      "Rate limiting, replay prevention, webhook IP allowlisting",
      "Audit logs and security event logging",
      "Streaming CSV exports for admin; VAT/WHT tax handling"
    ],
    "challenges": [
      "Designing for asynchronous M-Pesa flows without over-trusting callbacks",
      "Preventing voucher double-spend with conditional UPDATE in transaction",
      "Bounded self-healing without unbounded automation",
      "Kenya-specific VAT/WHT and mobile-first constraints"
    ],
    "outcomes": [
      "No inventory oversell; no voucher double-spend; no unaudited state changes",
      "Payment-safe: Daraja verification before any order/payment state update",
      "Self-healing with constrained automation and audit trail",
      "Production mindset: assume failure, verify asynchronously, automate carefully"
    ],
    "metrics": [
      { "label": "Status", "value": "~90â€“95%", "description": "Backend, DB, payments, healing, security complete" },
      { "label": "Payment", "value": "Verify first", "description": "STK Query before trusting callback" },
      { "label": "Voucher", "value": "Pessimistic", "description": "Conditional UPDATE in transaction" },
      { "label": "Audit", "value": "Immutable", "description": "Trail for every sensitive action" }
    ],
    "links": {
      "live": "",
      "github": "https://github.com/Ancel-duke/Aliv",
      "docs": "https://github.com/Ancel-duke/Aliv/blob/master/ARCHITECTURE.md"
    },
    "images": {
      "hero": "/assets/projects/fitsbyaliv.jpg",
      "before": "/assets/projects/fitsbyaliv.jpg",
      "after": "/assets/projects/fitsbyaliv.jpg",
      "gallery": [
        "/assets/projects/fitsbyaliv.jpg"
      ]
    }
  }
]

